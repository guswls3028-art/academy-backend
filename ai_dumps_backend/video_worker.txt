====================================================================================================
# BACKEND APP: video_worker
# ROOT PATH: C:\academy\apps\worker\video_worker
====================================================================================================


==========================================================================================
# FILE: config.py
==========================================================================================
# PATH: apps/worker/video_worker/config.py
from __future__ import annotations

import os
import sys
from dataclasses import dataclass


def _require(name: str) -> str:
    v = os.environ.get(name)
    if not v:
        raise RuntimeError(f"Missing required env: {name}")
    return v


def _require_any(*names: str) -> str:
    for name in names:
        v = os.environ.get(name)
        if v:
            return v
    raise RuntimeError(f"Missing required env (any of): {', '.join(names)}")


def _float(name: str, default: str) -> float:
    try:
        return float(os.environ.get(name, default))
    except Exception:
        return float(default)


def _int(name: str, default: str) -> int:
    try:
        return int(os.environ.get(name, default))
    except Exception:
        return int(default)


@dataclass(frozen=True)
class Config:
    # API / Auth
    API_BASE_URL: str
    INTERNAL_WORKER_TOKEN: str
    WORKER_ID: str

    # HTTP / retry
    HTTP_TIMEOUT_SECONDS: float
    RETRY_MAX_ATTEMPTS: int
    BACKOFF_BASE_SECONDS: float
    BACKOFF_CAP_SECONDS: float

    # Temp / Lock
    TEMP_DIR: str
    LOCK_DIR: str
    LOCK_STALE_SECONDS: int

    # Heartbeat
    HEARTBEAT_INTERVAL_SECONDS: int

    # ffmpeg / ffprobe
    FFMPEG_BIN: str
    FFPROBE_BIN: str
    FFPROBE_TIMEOUT_SECONDS: int
    FFMPEG_TIMEOUT_SECONDS: int

    # HLS / thumb
    HLS_TIME_SECONDS: int
    THUMBNAIL_AT_SECONDS: float
    MIN_SEGMENTS_PER_VARIANT: int

    # R2
    R2_BUCKET: str
    R2_PREFIX: str
    R2_ENDPOINT: str
    R2_ACCESS_KEY: str
    R2_SECRET_KEY: str
    R2_REGION: str
    UPLOAD_MAX_CONCURRENCY: int

    # download
    DOWNLOAD_TIMEOUT_SECONDS: float
    DOWNLOAD_CHUNK_BYTES: int


def load_config() -> Config:
    try:
        return Config(
            API_BASE_URL=_require("API_BASE_URL").rstrip("/"),
            INTERNAL_WORKER_TOKEN=_require("INTERNAL_WORKER_TOKEN"),
            WORKER_ID=os.environ.get("WORKER_ID", "video-worker"),

            HTTP_TIMEOUT_SECONDS=_float("VIDEO_WORKER_HTTP_TIMEOUT", "10.0"),
            RETRY_MAX_ATTEMPTS=_int("VIDEO_WORKER_RETRY_MAX", "6"),
            BACKOFF_BASE_SECONDS=_float("VIDEO_WORKER_BACKOFF_BASE", "0.5"),
            BACKOFF_CAP_SECONDS=_float("VIDEO_WORKER_BACKOFF_CAP", "10.0"),

            TEMP_DIR=os.environ.get("VIDEO_WORKER_TEMP_DIR", "/tmp/video-worker"),
            LOCK_DIR=os.environ.get("VIDEO_WORKER_LOCK_DIR", "/tmp/video-worker-locks"),
            LOCK_STALE_SECONDS=_int("VIDEO_WORKER_LOCK_STALE_SECONDS", "3600"),

            HEARTBEAT_INTERVAL_SECONDS=_int("VIDEO_WORKER_HEARTBEAT_INTERVAL", "20"),

            FFMPEG_BIN=os.environ.get("FFMPEG_BIN", "ffmpeg"),
            FFPROBE_BIN=os.environ.get("FFPROBE_BIN", "ffprobe"),
            FFPROBE_TIMEOUT_SECONDS=_int("FFPROBE_TIMEOUT_SECONDS", "60"),
            FFMPEG_TIMEOUT_SECONDS=_int("FFMPEG_TIMEOUT_SECONDS", "3600"),

            HLS_TIME_SECONDS=_int("HLS_TIME_SECONDS", "4"),
            THUMBNAIL_AT_SECONDS=_float("THUMBNAIL_AT_SECONDS", "1.0"),
            MIN_SEGMENTS_PER_VARIANT=_int("MIN_SEGMENTS_PER_VARIANT", "1"),

            R2_BUCKET=_require_any("R2_BUCKET", "R2_VIDEO_BUCKET"),
            R2_PREFIX=os.environ.get("R2_PREFIX", "media/hls/videos"),
            R2_ENDPOINT=_require("R2_ENDPOINT"),
            R2_ACCESS_KEY=_require("R2_ACCESS_KEY"),
            R2_SECRET_KEY=_require("R2_SECRET_KEY"),
            R2_REGION=os.environ.get("R2_REGION", "auto"),
            UPLOAD_MAX_CONCURRENCY=_int("UPLOAD_MAX_CONCURRENCY", "8"),

            DOWNLOAD_TIMEOUT_SECONDS=_float("DOWNLOAD_TIMEOUT_SECONDS", "30.0"),
            DOWNLOAD_CHUNK_BYTES=_int("DOWNLOAD_CHUNK_BYTES", str(1024 * 1024)),
        )
    except Exception as e:
        import logging
        logging.basicConfig(level=logging.INFO)
        logging.getLogger(__name__).critical("config error: %s", e)
        sys.exit(1)


==========================================================================================
# FILE: download.py
==========================================================================================
from __future__ import annotations

import logging
from pathlib import Path

import requests

from apps.worker.video_worker.config import Config
from apps.worker.video_worker.utils import backoff_sleep, ensure_dir, trim_tail

logger = logging.getLogger("video_worker")


class DownloadError(RuntimeError):
    pass


def download_to_file(*, url: str, dst: Path, cfg: Config) -> None:
    """
    안정적 다운로드:
    - stream chunk
    - retry with backoff
    - tmp(.part) -> atomic rename
    """
    ensure_dir(dst.parent)

    attempt = 0
    while True:
        try:
            with requests.get(url, stream=True, timeout=cfg.DOWNLOAD_TIMEOUT_SECONDS) as r:
                r.raise_for_status()

                tmp = dst.with_suffix(dst.suffix + ".part")
                bytes_written = 0

                with open(tmp, "wb") as f:
                    for chunk in r.iter_content(chunk_size=cfg.DOWNLOAD_CHUNK_BYTES):
                        if chunk:
                            f.write(chunk)
                            bytes_written += len(chunk)

                if bytes_written <= 0:
                    raise DownloadError("downloaded file is empty")

                tmp.replace(dst)
                return

        except Exception as e:
            attempt += 1
            if attempt >= cfg.RETRY_MAX_ATTEMPTS:
                raise DownloadError(f"download failed: {trim_tail(str(e))}") from e
            logger.warning("download retry attempt=%s err=%s", attempt, e)
            backoff_sleep(attempt, cfg.BACKOFF_BASE_SECONDS, cfg.BACKOFF_CAP_SECONDS)


==========================================================================================
# FILE: sqs_main.py
==========================================================================================
"""
Video Worker - SQS 기반 메인 엔트리포인트

기존 HTTP polling 방식에서 SQS Long Polling으로 전환
"""

from __future__ import annotations

import os
import sys

# Django 설정이 있으면 앱 로드 — 아래 import들이 Django 모델을 쓰므로 setup을 먼저 호출
if os.environ.get("DJANGO_SETTINGS_MODULE"):
    import django
    django.setup()

import json
import logging
import signal
import time
import uuid
from typing import Optional

import boto3
import requests

from apps.worker.video_worker.config import load_config
from libs.queue import QueueUnavailableError
from src.infrastructure.video import VideoSQSAdapter
from src.infrastructure.video.processor import process_video
from academy.adapters.db.django.repositories_video import DjangoVideoRepository
from src.infrastructure.cache.redis_idempotency_adapter import RedisIdempotencyAdapter
from src.infrastructure.cache.redis_progress_adapter import RedisProgressAdapter
from src.application.video.handler import ProcessVideoJobHandler

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] [VIDEO-WORKER-SQS] %(message)s",
)
logger = logging.getLogger("video_worker_sqs")

_shutdown = False
_current_job_receipt_handle: Optional[str] = None  # Graceful shutdown: 현재 처리 중인 작업 추적
_current_job_start_time: Optional[float] = None  # 로그 가시성: 작업 시작 시간

# SQS Long Polling 설정
SQS_WAIT_TIME_SECONDS = 20  # 최대 대기 시간 (Long Polling)
# 작업 시작 시 ChangeMessageVisibility로 연장 (3시간 영상 등 장시간 대비)
VIDEO_VISIBILITY_EXTEND_SECONDS = int(os.getenv("VIDEO_SQS_VISIBILITY_EXTEND", "10800"))  # 3시간
SQS_VISIBILITY_TIMEOUT = 300  # 로그 비교용 (실제는 VIDEO_VISIBILITY_EXTEND_SECONDS 사용)

# EC2 Self-Stop 설정 (비용 최적화)
IDLE_STOP_THRESHOLD = int(os.getenv("EC2_IDLE_STOP_THRESHOLD", "5"))  # 연속 빈 폴링 5회 = 100초


def _handle_signal(sig, frame):
    """
    Graceful shutdown 핸들러
    
    50명 원장 확장 대비: 현재 처리 중인 작업 완료 후 종료
    """
    global _shutdown, _current_job_receipt_handle
    signal_name = signal.Signals(sig).name
    logger.info(
        "Received %s, initiating graceful shutdown... | current_job=%s",
        signal_name,
        "processing" if _current_job_receipt_handle else "idle",
    )
    _shutdown = True
    # 현재 작업이 있으면 완료될 때까지 대기 (메인 루프에서 처리)


def _stop_self_ec2() -> None:
    """
    SQS 큐가 연속으로 비어있을 때 EC2 인스턴스 자동 종료
    
    비용 최적화: idle 상태 인스턴스 자동 종료로 월 $30-50 절감
    IMDSv2를 사용하여 안전하게 인스턴스 메타데이터 조회
    """
    try:
        # EC2 메타데이터에서 인스턴스 정보 가져오기 (IMDSv2)
        token = requests.put(
            "http://169.254.169.254/latest/api/token",
            headers={"X-aws-ec2-metadata-token-ttl-seconds": "21600"},
            timeout=2,
        ).text
        
        headers = {"X-aws-ec2-metadata-token": token}
        instance_id = requests.get(
            "http://169.254.169.254/latest/meta-data/instance-id",
            headers=headers,
            timeout=2,
        ).text
        
        region = requests.get(
            "http://169.254.169.254/latest/meta-data/placement/region",
            headers=headers,
            timeout=2,
        ).text
        
        ec2 = boto3.client("ec2", region_name=region)
        ec2.stop_instances(InstanceIds=[instance_id])
        
        logger.info("EC2 instance stopped due to idle queues: instance_id=%s (video worker)", instance_id)
        
    except Exception as e:
        logger.exception("EC2 self-stop failed (ignored): %s", e)


def main() -> int:
    """
    SQS 기반 Video Worker 메인 루프
    
    Flow:
    1. SQS에서 메시지 Long Polling
    2. 메시지 수신 시 비디오 처리
    3. 성공 시 메시지 삭제
    4. 실패 시 메시지는 SQS가 자동으로 재시도 (DLQ로 전송 전까지)
    """
    signal.signal(signal.SIGTERM, _handle_signal)
    signal.signal(signal.SIGINT, _handle_signal)
    
    cfg = load_config()
    queue = VideoSQSAdapter()
    repo = DjangoVideoRepository()
    idempotency = RedisIdempotencyAdapter()
    progress = RedisProgressAdapter()
    handler = ProcessVideoJobHandler(
        repo=repo,
        idempotency=idempotency,
        progress=progress,
        process_fn=process_video,
    )

    logger.info(
        "Video Worker (SQS) started | queue=%s | wait_time=%ss",
        queue._get_queue_name(),
        SQS_WAIT_TIME_SECONDS,
    )
    
    consecutive_errors = 0
    max_consecutive_errors = 10
    consecutive_empty_polls = 0  # 비용 최적화: 빈 폴링 카운터
    
    try:
        while not _shutdown:
            try:
                # SQS Long Polling으로 메시지 수신
                try:
                    message = queue.receive_message(wait_time_seconds=SQS_WAIT_TIME_SECONDS)
                except QueueUnavailableError as e:
                    # 로컬 등 AWS 자격 증명 없을 때: 로그 한 번, 60초 대기 후 재시도 (empty로 세지 않음 → EC2 종료 안 함)
                    logger.warning(
                        "SQS unavailable (AWS credentials invalid or missing?). Waiting 60s before retry. %s",
                        e,
                    )
                    time.sleep(60)
                    continue

                if not message:
                    consecutive_empty_polls += 1
                    consecutive_errors = 0

                    # 연속 빈 폴링이 임계값을 초과하면 EC2 인스턴스 종료 (실제 큐가 비었을 때만)
                    if consecutive_empty_polls >= IDLE_STOP_THRESHOLD:
                        logger.info(
                            "Queue empty for %d consecutive polls (threshold=%d), stopping EC2 instance in 10s",
                            consecutive_empty_polls,
                            IDLE_STOP_THRESHOLD,
                        )
                        time.sleep(10)  # 500 plan: Dead zone 완화를 위해 Stop 직전 대기
                        logger.info("EC2 self-stop initiating (video worker)")
                        _stop_self_ec2()
                        return 0

                    continue

                # 메시지가 있으면 카운터 리셋
                consecutive_empty_polls = 0
                
                receipt_handle = message.get("receipt_handle")
                if not receipt_handle:
                    logger.error("Message missing receipt_handle: %s", message)
                    continue

                # ----- R2 삭제 작업 (비동기 삭제) -----
                if message.get("action") == "delete_r2":
                    video_id = message.get("video_id")
                    file_key = (message.get("file_key") or "").strip()
                    hls_prefix = (message.get("hls_prefix") or "").strip()
                    # delete_r2 전용 visibility 900초. 장시간 삭제 시 배치마다 재연장.
                    DELETE_R2_VISIBILITY = 900
                    queue.change_message_visibility(receipt_handle, DELETE_R2_VISIBILITY)
                    # action별 멱등: 삭제 중복 처리 방지
                    if not idempotency.acquire_lock(f"delete_r2:{video_id}"):
                        logger.info("R2 delete skip (lock) video_id=%s", video_id)
                        queue.delete_message(receipt_handle)
                        continue
                    try:
                        from apps.infrastructure.storage.r2 import delete_object_r2_video, delete_prefix_r2_video
                        if file_key:
                            delete_object_r2_video(key=file_key)
                            logger.info("R2 raw deleted video_id=%s key=%s", video_id, file_key)
                        if hls_prefix:
                            def _extend_visibility(_):
                                queue.change_message_visibility(receipt_handle, DELETE_R2_VISIBILITY)
                            n = delete_prefix_r2_video(
                                prefix=hls_prefix,
                                on_batch_deleted=_extend_visibility,
                            )
                            logger.info("R2 HLS prefix deleted video_id=%s prefix=%s count=%d", video_id, hls_prefix, n)
                    except Exception as e:
                        logger.exception("R2 delete job failed video_id=%s: %s", video_id, e)
                    finally:
                        idempotency.release_lock(f"delete_r2:{video_id}")
                    queue.delete_message(receipt_handle)
                    continue

                # ----- 인코딩 작업 -----
                video_id = message.get("video_id")
                file_key = message.get("file_key")
                tenant_id = message.get("tenant_id")
                tenant_code = message.get("tenant_code")
                message_created_at = message.get("created_at")

                if not video_id or tenant_id is None:
                    logger.error("Invalid message format (video_id, tenant_id required): %s", message)
                    queue.delete_message(receipt_handle)
                    continue

                # Retry로 이미 완료된 영상이면 visibility 연장 없이 메시지만 삭제 (중복·3시간 묶임 방지)
                from academy.adapters.db.django.repositories_video import get_video_status
                if get_video_status(video_id) == "READY":
                    queue.delete_message(receipt_handle)
                    logger.info("VIDEO_ALREADY_READY_SKIP | video_id=%s (retry 등으로 이미 완료)", video_id)
                    continue

                # 장시간 인코딩 시 재노출 방지 (작업 시작 직후 visibility 연장)
                queue.change_message_visibility(receipt_handle, VIDEO_VISIBILITY_EXTEND_SECONDS)

                request_id = str(uuid.uuid4())[:8]
                message_received_at = time.time()
                queue_wait_time = message_received_at - (float(message_created_at) if message_created_at else message_received_at)

                logger.info(
                    "SQS_MESSAGE_RECEIVED | request_id=%s | video_id=%s | tenant_id=%s | queue_wait_sec=%.2f | created_at=%s",
                    request_id,
                    video_id,
                    tenant_id,
                    queue_wait_time,
                    message_created_at or "unknown",
                )

                global _current_job_receipt_handle, _current_job_start_time
                _current_job_receipt_handle = receipt_handle
                _current_job_start_time = time.time()

                job = {
                    "video_id": int(video_id),
                    "file_key": str(file_key or ""),
                    "tenant_id": int(tenant_id),
                    "tenant_code": str(tenant_code or ""),
                }

                try:
                    result = handler.handle(job, cfg)
                except Exception as e:
                    # handler.handle() 예외 시에도 반드시 즉시 재노출 (3시간 묶임 방지)
                    queue.change_message_visibility(receipt_handle, 0)
                    logger.exception("Handler exception (visibility 0 applied): video_id=%s: %s", video_id, e)
                    consecutive_errors += 1
                    _current_job_receipt_handle = None
                    _current_job_start_time = None
                    if consecutive_errors >= max_consecutive_errors:
                        logger.error("Too many consecutive errors (%s), shutting down", consecutive_errors)
                        return 1
                    time.sleep(5)
                    continue

                processing_duration = time.time() - _current_job_start_time
                _current_job_receipt_handle = None
                _current_job_start_time = None

                if result == "ok":
                    # 인코딩 성공 → HLS 업로드·DB 완료 후 raw 삭제 (실패해도 DB 롤백 안 함, 재시도만)
                    file_key_for_raw = job.get("file_key") or ""
                    if file_key_for_raw.strip():
                        from apps.infrastructure.storage.r2 import delete_object_r2_video
                        for attempt in range(3):
                            try:
                                delete_object_r2_video(key=file_key_for_raw.strip())
                                logger.info("R2 raw deleted after encode video_id=%s key=%s", video_id, file_key_for_raw[:80])
                                break
                            except Exception as e:
                                logger.warning(
                                    "R2 raw delete after encode failed video_id=%s attempt=%s: %s",
                                    video_id, attempt + 1, e,
                                )
                                if attempt < 2:
                                    time.sleep(2**attempt)  # 1s → 2s → 4s exponential backoff
                    queue.delete_message(receipt_handle)
                    logger.info(
                        "SQS_JOB_COMPLETED | request_id=%s | video_id=%s | tenant_code=%s | processing_duration=%.2f | queue_wait_sec=%.2f",
                        request_id,
                        video_id,
                        tenant_code,
                        processing_duration,
                        queue_wait_time,
                    )
                    # 평균 인코딩 시간 모니터링용 (로그 파싱·메트릭 수집)
                    logger.info(
                        "VIDEO_ENCODING_DURATION | video_id=%s | duration_sec=%.2f",
                        video_id,
                        processing_duration,
                    )
                    consecutive_errors = 0

                    if _shutdown:
                        logger.info("Graceful shutdown: current job completed, exiting")
                        break

                elif result == "skip":
                    queue.delete_message(receipt_handle)
                    consecutive_errors = 0

                else:
                    # handler 실패 시 즉시 재노출 → 다른 워커가 곧바로 처리 (3시간 묶임 방지)
                    queue.change_message_visibility(receipt_handle, 0)
                    logger.exception(
                        "SQS_JOB_FAILED | request_id=%s | video_id=%s | tenant_code=%s | processing_duration=%.2f | queue_wait_sec=%.2f",
                        request_id,
                        video_id,
                        tenant_code,
                        processing_duration,
                        queue_wait_time,
                    )
                    if processing_duration > SQS_VISIBILITY_TIMEOUT:
                        logger.warning(
                            "SQS_VISIBILITY_TIMEOUT_EXCEEDED | request_id=%s | video_id=%s | processing_duration=%.2f | visibility_timeout=%d",
                            request_id,
                            video_id,
                            processing_duration,
                            SQS_VISIBILITY_TIMEOUT,
                        )
                    consecutive_errors += 1

                    if consecutive_errors >= max_consecutive_errors:
                        logger.error(
                            "Too many consecutive errors (%s), shutting down",
                            consecutive_errors,
                        )
                        return 1
                
            except KeyboardInterrupt:
                logger.info("Keyboard interrupt received")
                break
            except Exception as e:
                # 예외 발생 시에도 visibility 0 시도 (이미 delete된 메시지면 API 오류는 무시)
                try:
                    queue.change_message_visibility(receipt_handle, 0)
                except Exception:
                    pass
                logger.exception("Unexpected error in main loop: %s", e)
                consecutive_errors += 1
                if consecutive_errors >= max_consecutive_errors:
                    logger.error(
                        "Too many consecutive errors (%s), shutting down",
                        consecutive_errors,
                    )
                    return 1
                time.sleep(5)
        
        # Graceful shutdown: 현재 작업이 있으면 완료 대기
        if _current_job_receipt_handle:
            logger.info(
                "Graceful shutdown: waiting for current job to complete | receipt_handle=%s",
                _current_job_receipt_handle[:20] + "...",
            )
        
        logger.info("Video Worker shutdown complete")
        return 0
        
    except Exception:
        logger.exception("Fatal error in Video Worker")
        return 1


if __name__ == "__main__":
    sys.exit(main())


==========================================================================================
# FILE: utils.py
==========================================================================================
from __future__ import annotations

import logging
import random
import shutil
import tempfile
import time
from contextlib import contextmanager
from pathlib import Path

logger = logging.getLogger("video_worker")


@contextmanager
def temp_workdir(base_dir: str, prefix: str):
    """
    Temporary working directory context manager.
    
    Ensures cleanup on exit (success or failure).
    Logs errors if cleanup fails.
    """
    Path(base_dir).mkdir(parents=True, exist_ok=True)
    path = Path(tempfile.mkdtemp(prefix=prefix, dir=base_dir))
    try:
        yield path
    finally:
        try:
            if path.exists():
                shutil.rmtree(path, ignore_errors=False)
                logger.debug("Cleaned up temp dir: %s", path)
        except Exception as e:
            logger.error("Failed to cleanup temp dir: %s, error: %s", path, e)
            # Don't re-raise - allow processing to continue, but log error for monitoring


def ensure_dir(path: Path) -> None:
    path.mkdir(parents=True, exist_ok=True)


def backoff_sleep(attempt: int, base: float, cap: float) -> None:
    raw = min(cap, base * (2 ** attempt))
    jitter = random.uniform(0.5, 1.5)
    time.sleep(raw * jitter)


def trim_tail(s: str, limit: int = 2000) -> str:
    if not s:
        return ""
    return s[-limit:] if len(s) > limit else s


def guess_content_type(name: str) -> str:
    n = name.lower()
    if n.endswith(".m3u8"):
        return "application/vnd.apple.mpegurl"
    if n.endswith(".ts"):
        return "video/MP2T"
    if n.endswith(".mp4"):
        return "video/mp4"
    if n.endswith(".jpg") or n.endswith(".jpeg"):
        return "image/jpeg"
    if n.endswith(".png"):
        return "image/png"
    if n.endswith(".json"):
        return "application/json"
    return "application/octet-stream"


def cache_control_for_object(name: str) -> str:
    """
    R2 Cache-Control 전략 (요구사항 반영)

    - HLS playlist (.m3u8): 서명 정책/쿠키 기반 접근을 전제로 "no-cache"
      (플레이리스트는 재생 정책/토큰 갱신 영향 받음)
    - Segment (.ts): immutable (콘텐츠 주소가 prefix/video_id 고정이라도,
      세그먼트는 VOD 생성 후 변경되지 않는 것이 정상)
    - Thumbnail: 7d 캐시
    """
    n = name.lower()
    if n.endswith(".m3u8"):
        return "no-cache"
    if n.endswith(".ts"):
        return "public, max-age=31536000, immutable"
    if n.endswith(".jpg") or n.endswith(".jpeg") or n.endswith(".png"):
        return "public, max-age=604800"
    return "public, max-age=3600"


==========================================================================================
# FILE: video/duration.py
==========================================================================================
# PATH: apps/worker/video_worker/video/duration.py
#
# PURPOSE:
# - 로컬 영상 파일에서 ffprobe로 duration(초) 추출
# - 실패해도 worker 전체 작업을 fail 시키지 않음 (best-effort)

from __future__ import annotations

import subprocess
from typing import Optional


class DurationProbeError(RuntimeError):
    pass


def probe_duration_seconds(
    *,
    input_path: str,
    ffprobe_bin: str,
    timeout: int,
) -> Optional[int]:
    if not input_path:
        return None

    cmd = [
        ffprobe_bin,
        "-v", "error",
        "-show_entries", "format=duration",
        "-of", "default=noprint_wrappers=1:nokey=1",
        input_path,
    ]

    try:
        p = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=timeout,
            check=False,
        )
    except Exception:
        return None

    if p.returncode != 0:
        return None

    raw = (p.stdout or "").strip()
    if not raw:
        return None

    try:
        sec = float(raw)
        if sec < 0:
            return None
        return int(sec)
    except Exception:
        return None


==========================================================================================
# FILE: video/r2_uploader.py
==========================================================================================
from __future__ import annotations

import os
from pathlib import Path

import boto3
from boto3.s3.transfer import TransferConfig

from apps.worker.video_worker.utils import guess_content_type, cache_control_for_object, trim_tail, backoff_sleep


class UploadError(RuntimeError):
    pass


def upload_directory(
    *,
    local_dir: Path,
    bucket: str,
    prefix: str,
    endpoint_url: str,
    access_key: str,
    secret_key: str,
    region: str,
    max_concurrency: int,
    retry_max: int = 5,
    backoff_base: float = 0.5,
    backoff_cap: float = 10.0,
) -> None:
    """
    업로드 정책 (요구사항 반영):
    - Content-Type 정확히
    - Cache-Control 전략 포함
      - .m3u8 : no-cache
      - .ts   : public, max-age=31536000, immutable
      - thumb : 7d
    - 부분 업로드 방지:
      - boto3 multipart 실패 시 예외 / retry
      - 동일 Key에 overwrite는 허용 (idempotent)
    """
    s3 = boto3.client(
        "s3",
        endpoint_url=endpoint_url,
        aws_access_key_id=access_key,
        aws_secret_access_key=secret_key,
        region_name=region,
    )

    transfer_cfg = TransferConfig(
        max_concurrency=max_concurrency,
        multipart_threshold=8 * 1024 * 1024,
        multipart_chunksize=8 * 1024 * 1024,
        use_threads=True,
    )

    local_dir = local_dir.resolve()

    for root, _, files in os.walk(local_dir):
        for name in files:
            full_path = Path(root) / name
            rel = full_path.relative_to(local_dir)
            key = f"{prefix.rstrip('/')}/{rel.as_posix()}"

            extra = {
                "ContentType": guess_content_type(name),
                "CacheControl": cache_control_for_object(name),
            }

            attempt = 0
            while True:
                try:
                    s3.upload_file(
                        Filename=str(full_path),
                        Bucket=bucket,
                        Key=key,
                        ExtraArgs=extra,
                        Config=transfer_cfg,
                    )
                    break
                except Exception as e:
                    attempt += 1
                    if attempt >= retry_max:
                        raise UploadError(f"upload failed key={key} err={trim_tail(str(e))}") from e
                    backoff_sleep(attempt, backoff_base, backoff_cap)


==========================================================================================
# FILE: video/thumbnail.py
==========================================================================================
from __future__ import annotations

import subprocess
from pathlib import Path

from apps.worker.video_worker.utils import ensure_dir, trim_tail


class ThumbnailError(RuntimeError):
    pass


def generate_thumbnail(
    *,
    input_path: str,
    output_path: Path,
    ffmpeg_bin: str,
    at_seconds: float,
    timeout: int,
) -> None:
    ensure_dir(output_path.parent)

    cmd = [
        ffmpeg_bin,
        "-y",
        "-ss", f"{at_seconds:.3f}",
        "-i", input_path,
        "-frames:v", "1",
        "-q:v", "2",
        str(output_path),
    ]

    try:
        p = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=timeout,
            check=False,
        )
    except subprocess.TimeoutExpired as e:
        raise ThumbnailError(f"thumbnail timeout ({timeout}s)") from e

    if p.returncode != 0:
        raise ThumbnailError(f"thumbnail ffmpeg failed: {trim_tail(p.stderr)}")


==========================================================================================
# FILE: video/transcoder.py
==========================================================================================
# PATH: apps/worker/video_worker/video/transcoder.py

from __future__ import annotations

import json
import subprocess
from pathlib import Path
from typing import List, Optional

from apps.worker.video_worker.utils import ensure_dir, trim_tail

# preset 유지 (순서 중요)
HLS_VARIANTS = [
    {"name": "1", "width": 426, "height": 240, "video_bitrate": "400k", "audio_bitrate": "64k"},
    {"name": "2", "width": 640, "height": 360, "video_bitrate": "800k", "audio_bitrate": "96k"},
    {"name": "3", "width": 1280, "height": 720, "video_bitrate": "2500k", "audio_bitrate": "128k"},
]


class TranscodeError(RuntimeError):
    pass


def _probe_resolution(input_path: str, ffprobe_bin: str, timeout: int) -> tuple[int, int]:
    cmd = [
        ffprobe_bin,
        "-v", "error",
        "-select_streams", "v:0",
        "-show_entries", "stream=width,height",
        "-of", "json",
        input_path,
    ]
    try:
        p = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=timeout,
            check=False,
        )
    except subprocess.TimeoutExpired:
        return 0, 0

    if p.returncode != 0:
        return 0, 0

    try:
        data = json.loads(p.stdout)
        s = (data.get("streams") or [{}])[0]
        return int(s.get("width") or 0), int(s.get("height") or 0)
    except Exception:
        return 0, 0


def _select_variants(input_w: int, input_h: int) -> List[dict]:
    """
    입력 해상도 상한 반영:
    - 원본보다 큰 variant는 제외
    """
    selected = []
    for v in HLS_VARIANTS:
        if v["width"] <= input_w and v["height"] <= input_h:
            selected.append(v)
    # 안전장치: 최소 1개
    if not selected:
        selected.append(HLS_VARIANTS[0])
    return selected


def prepare_output_dirs(output_root: Path, variants: List[dict]) -> None:
    ensure_dir(output_root)
    for v in variants:
        ensure_dir(output_root / f"v{v['name']}")


def has_audio_stream(*, input_path: str, ffprobe_bin: str, timeout: int) -> bool:
    cmd = [
        ffprobe_bin,
        "-v", "error",
        "-print_format", "json",
        "-show_streams",
        input_path,
    ]
    try:
        p = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=timeout,
            check=False,
        )
    except subprocess.TimeoutExpired:
        return False

    if p.returncode != 0:
        return False

    try:
        data = json.loads(p.stdout)
        streams = data.get("streams") or []
        return any(s.get("codec_type") == "audio" for s in streams)
    except Exception:
        return False


def build_filter_complex(variants: List[dict]) -> str:
    parts: List[str] = []
    split_count = len(variants)
    parts.append("[0:v]split={}".format(split_count) + "".join(f"[v{i}]" for i in range(split_count)))
    for i, v in enumerate(variants):
        parts.append(f"[v{i}]scale={v['width']}:{v['height']}[v{i}out]")
    return ";".join(parts)


def build_ffmpeg_command(
    *,
    input_path: str,
    variants: List[dict],
    with_audio: bool,
    ffmpeg_bin: str,
    hls_time: int,
) -> List[str]:
    cmd: List[str] = [
        ffmpeg_bin,
        "-y",
        "-i", input_path,
        "-filter_complex", build_filter_complex(variants),
    ]

    for i, v in enumerate(variants):
        cmd += ["-map", f"[v{i}out]"]
        if with_audio:
            cmd += ["-map", "0:a?"]

        cmd += [
            f"-c:v:{i}", "libx264",
            "-profile:v", "main",
            "-pix_fmt", "yuv420p",
            f"-b:v:{i}", v["video_bitrate"],
            "-g", "48",
            "-keyint_min", "48",
            "-sc_threshold", "0",
        ]

        if with_audio:
            cmd += [
                f"-c:a:{i}", "aac",
                "-ac", "2",
                f"-b:a:{i}", v["audio_bitrate"],
            ]

    if with_audio:
        var_map = " ".join(f"v:{i},a:{i},name:{v['name']}" for i, v in enumerate(variants))
    else:
        var_map = " ".join(f"v:{i},name:{v['name']}" for i, v in enumerate(variants))

    cmd += [
        "-f", "hls",
        "-hls_time", str(hls_time),
        "-hls_playlist_type", "vod",
        "-hls_flags", "independent_segments",
        "-hls_segment_filename", "v%v/index%d.ts",
        "-master_pl_name", "master.m3u8",
        "-var_stream_map", var_map,
        "v%v/index.m3u8",
    ]
    return cmd


def transcode_to_hls(
    *,
    video_id: int,
    input_path: str,
    output_root: Path,
    ffmpeg_bin: str,
    ffprobe_bin: str,
    hls_time: int,
    timeout: Optional[int],
) -> Path:
    # 입력 해상도 기반 variant 선택
    w, h = _probe_resolution(input_path, ffprobe_bin, min(60, int(timeout or 60)))
    variants = _select_variants(w, h)

    prepare_output_dirs(output_root, variants)

    with_audio = has_audio_stream(
        input_path=input_path,
        ffprobe_bin=ffprobe_bin,
        timeout=min(60, int(timeout or 60)),
    )

    cmd = build_ffmpeg_command(
        input_path=input_path,
        variants=variants,
        with_audio=with_audio,
        ffmpeg_bin=ffmpeg_bin,
        hls_time=hls_time,
    )

    try:
        p = subprocess.run(
            cmd,
            cwd=str(output_root.resolve()),
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=timeout,
            check=False,
        )
    except subprocess.TimeoutExpired as e:
        raise TranscodeError(f"ffmpeg timeout video_id={video_id} seconds={timeout}") from e

    if p.returncode != 0:
        raise TranscodeError(
            f"ffmpeg failed video_id={video_id} with_audio={with_audio} stderr={trim_tail(p.stderr)}"
        )

    master = output_root / "master.m3u8"
    if not master.exists():
        raise TranscodeError("master.m3u8 not created")

    return master


==========================================================================================
# FILE: video/validate.py
==========================================================================================
# PATH: apps/worker/video_worker/video/validate.py

from __future__ import annotations

from pathlib import Path


def validate_hls_output(root: Path, min_segments: int) -> None:
    """
    인코딩 결과 깨짐 자동 fail 처리용 검증:
    - master.m3u8 존재
    - 각 variant playlist 존재
    - 각 variant에 최소 세그먼트 수 확보

    상품 레벨 보정:
    - 짧은 영상(총 길이 < min_segments * HLS_TIME)의 경우
      ffmpeg 정상 동작에서도 세그먼트 수가 min보다 작을 수 있음
    - 따라서 "0개"만 실패로 간주하고, 1개 이상이면 정상 처리
    """
    master = root / "master.m3u8"
    if not master.exists():
        raise RuntimeError("master.m3u8 missing")

    variants = list(root.glob("v*/index.m3u8"))
    if not variants:
        raise RuntimeError("no variant playlists (v*/index.m3u8)")

    for v in variants:
        segs = list(v.parent.glob("*.ts"))

        # 기존: 고정 min_segments 강제
        # if len(segs) < int(min_segments):
        #     raise RuntimeError(f"HLS validation failed: {v} segments={len(segs)} min={min_segments}")

        # MODIFIED: 짧은 영상 허용 (세그먼트 1개 이상이면 정상)
        if len(segs) <= 0:  # MODIFIED
            raise RuntimeError(  # MODIFIED
                f"HLS validation failed: {v} segments={len(segs)} min=1"  # MODIFIED
            )
