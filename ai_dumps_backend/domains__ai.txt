====================================================================================================
# BACKEND APP: domains__ai
# ROOT PATH: C:\academy\apps\domains\ai
====================================================================================================


==========================================================================================
# FILE: __init__.py
==========================================================================================
# apps/domains/ai/__init__.py


==========================================================================================
# FILE: apps.py
==========================================================================================
# apps/domains/ai/apps.py
from django.apps import AppConfig


class AIDomainConfig(AppConfig):
    default_auto_field = "django.db.models.BigAutoField"
    name = "apps.domains.ai"
    label = "ai_domain"


==========================================================================================
# FILE: callbacks.py
==========================================================================================
# apps/domains/ai/callbacks.py
from apps.shared.contracts.ai_result import AIResult
from apps.domains.ai.models import AIJobModel
from apps.domains.submissions.services.ai_omr_result_mapper import apply_ai_result
from apps.domains.results.tasks.grading_tasks import grade_submission_task


def handle_ai_result(result: AIResult) -> None:
    """
    Worker → API callback entry

    규칙(무퇴화/정규화):
    - 상태(status) 변경은 Queue/API(InternalAIJobResultView + DBJobQueue)가 SSOT로 처리한다.
    - callbacks는 "도메인 후속 처리"만 담당한다.
    - 결과 fact(AIResultModel)는 API 계층에서 이미 저장되므로 여기서 생성/수정하지 않는다.
    """
    # callbacks가 job 존재를 전제로 동작 (gateway에서 job row를 선생성)
    AIJobModel.objects.get(job_id=result.job_id)

    if result.status == "FAILED":
        # 실패 상태/에러/재시도는 API + DBJobQueue에서 처리됨
        return

    # DONE: submissions 로 위임 (답안 중간산물 저장)
    payload = result.result if isinstance(result.result, dict) else {}
    submission_id = apply_ai_result(payload)

    # 채점 job enqueue (results 책임)
    if submission_id:
        grade_submission_task.delay(int(submission_id))


==========================================================================================
# FILE: gateway.py
==========================================================================================
from __future__ import annotations

from typing import Any, Dict, Optional

from apps.shared.contracts.ai_job import AIJob
from apps.domains.ai.types import ensure_payload_dict, AIJobType
from apps.domains.ai.safe import safe_dispatch
from apps.domains.ai.queueing.publisher import publish_job
from apps.domains.ai.models import AIJobModel


def dispatch_job(
    *,
    job_type: AIJobType,
    payload: Dict[str, Any],
    tenant_id: Optional[str] = None,
    source_domain: Optional[str] = None,
    source_id: Optional[str] = None,
) -> Dict[str, Any]:
    payload = ensure_payload_dict(payload)

    job = AIJob.new(
        type=job_type,
        payload=payload,
        tenant_id=tenant_id,
        source_domain=source_domain,
        source_id=source_id,
    )

    def _do():
        # ✅ callbacks가 AIJobModel을 조회하므로, 발행 시점에 반드시 저장
        job_model = AIJobModel.objects.create(
            job_id=job.id,
            job_type=job.type,
            payload=job.payload,
            status="PENDING",
            tenant_id=tenant_id,
            source_domain=source_domain,
            source_id=source_id,
        )

        try:
            publish_job(job)
        except Exception as e:
            job_model.status = "FAILED"
            job_model.error_message = str(e)
            job_model.last_error = str(e)
            job_model.save(update_fields=["status", "error_message", "last_error", "updated_at"])
            raise

        return {"ok": True, "job_id": job.id, "type": job.type}

    return safe_dispatch(_do, fallback={"ok": False, "job_id": job.id, "type": job.type})


==========================================================================================
# FILE: models.py
==========================================================================================
# apps/domains/ai/models.py
from __future__ import annotations

from django.db import models
from django.utils import timezone

from apps.api.common.models import BaseModel


class AIJobModel(BaseModel):
    """
    AI Job Meta (DB is SSOT)
    - API server owns lifecycle
    - Worker pulls via internal endpoints
    """

    job_id = models.CharField(max_length=64, unique=True)
    job_type = models.CharField(max_length=50)

    status = models.CharField(
        max_length=20,
        choices=[
            ("PENDING", "PENDING"),
            ("RUNNING", "RUNNING"),
            ("DONE", "DONE"),
            ("FAILED", "FAILED"),
        ],
        default="PENDING",
    )

    payload = models.JSONField(default=dict, blank=True)
    error_message = models.TextField(blank=True, default="")

    # ---- routing / trace ----
    tenant_id = models.CharField(max_length=64, null=True, blank=True)
    source_domain = models.CharField(max_length=64, null=True, blank=True)
    source_id = models.CharField(max_length=64, null=True, blank=True)

    # ---- retry / lease ----
    attempt_count = models.IntegerField(default=0)
    max_attempts = models.IntegerField(default=5)

    locked_by = models.CharField(max_length=128, null=True, blank=True)
    locked_at = models.DateTimeField(null=True, blank=True)
    lease_expires_at = models.DateTimeField(null=True, blank=True)
    last_heartbeat_at = models.DateTimeField(null=True, blank=True)

    next_run_at = models.DateTimeField(default=timezone.now)
    last_error = models.TextField(blank=True, default="")

    class Meta:
        db_table = "ai_job"
        indexes = [
            models.Index(fields=["status", "next_run_at"], name="ai_job_status_next_run_idx"),
            models.Index(fields=["lease_expires_at"], name="ai_job_lease_idx"),
            models.Index(fields=["source_domain", "source_id"], name="ai_job_source_idx"),
        ]

    def __str__(self) -> str:
        return f"AIJobModel<{self.job_id}>({self.job_type})[{self.status}]"


class AIResultModel(BaseModel):
    """
    AI Result Fact (write-once, idempotency anchor)
    - OneToOne to enforce single fact row per job
    """

    job = models.OneToOneField(
        AIJobModel,
        on_delete=models.CASCADE,
        related_name="result",
    )
    payload = models.JSONField(null=True, blank=True)

    class Meta:
        db_table = "ai_result"

    def __str__(self) -> str:
        return f"AIResultModel(job_id={self.job_id})"


==========================================================================================
# FILE: safe.py
==========================================================================================
# apps/domains/ai/safe.py
from __future__ import annotations

import logging
from typing import Any, Dict, Optional

logger = logging.getLogger(__name__)


def safe_dispatch(fn, *, fallback: Optional[Dict[str, Any]] = None, **kwargs) -> Dict[str, Any]:
    """
    AI Job 발행을 안전하게 감싼다.
    API는 실패해도 깨지면 안 된다.
    """
    try:
        return fn(**kwargs)
    except Exception as e:
        logger.exception("AI job dispatch failed", exc_info=e)
        return fallback or {"ok": False, "error": str(e)}


==========================================================================================
# FILE: types.py
==========================================================================================
from __future__ import annotations

from typing import Any, Dict, Literal, Optional, TypedDict


AIJobType = Literal[
    "ocr",
    "question_segmentation",
    "handwriting_analysis",
    "embedding",
    "problem_generation",
    "homework_video_analysis",
]


class OCRPayload(TypedDict, total=False):
    image_path: str
    engine: Optional[Literal["google", "tesseract", "auto"]]
    academy_id: Optional[int]


class SegmentationPayload(TypedDict, total=False):
    image_path: str
    engine: Optional[Literal["yolo", "opencv", "template", "auto"]]


class HandwritingPayload(TypedDict, total=False):
    image_path: str


class EmbeddingPayload(TypedDict, total=False):
    texts: list[str]
    backend: Optional[Literal["local", "openai", "auto"]]


class ProblemGenerationPayload(TypedDict, total=False):
    ocr_text: str
    model: Optional[str]


class HomeworkVideoPayload(TypedDict, total=False):
    video_path: str
    frame_stride: Optional[int]
    min_frame_count: Optional[int]


def ensure_payload_dict(payload: Any) -> Dict[str, Any]:
    if payload is None:
        return {}
    if isinstance(payload, dict):
        return payload
    raise TypeError("payload must be a dict")


==========================================================================================
# FILE: urls.py
==========================================================================================
# PATH: apps/domains/ai/urls.py
from django.urls import path

from apps.domains.ai.views.internal_ai_job_view import (
    InternalAIJobNextView,
    InternalAIJobResultView,
)

urlpatterns = [
    path("job/next/", InternalAIJobNextView.as_view(), name="internal-ai-job-next"),
    path("job/result/", InternalAIJobResultView.as_view(), name="internal-ai-job-result"),
]


==========================================================================================
# FILE: legacy/readme.md
==========================================================================================
legacy파일은 실제로 사용되지않는다.
구현 기능이식 체크리스트 점검용으로 존재만한다.


==========================================================================================
# FILE: legacy/views.py
==========================================================================================
# PATH: apps/api/v1/internal/ai/views.py
from __future__ import annotations

import json
import logging
import os
from typing import Any, Dict, Optional

from django.conf import settings
from django.http import JsonResponse
from django.views.decorators.http import require_http_methods
from django.views.decorators.csrf import csrf_exempt
from django.utils import timezone

import redis  # legacy 유지

from apps.shared.contracts.ai_job import AIJob

from apps.domains.ai.models import AIJobModel, AIResultModel
from apps.domains.ai.queueing.db_queue import DBJobQueue

from apps.domains.submissions.services.ai_result_router import apply_ai_result_for_submission
from apps.domains.results.tasks.grading_tasks import grade_submission_task


logger = logging.getLogger(__name__)


# -------------------------
# Legacy Redis (삭제 금지)
# -------------------------
def _redis() -> redis.Redis:
    return redis.from_url(settings.REDIS_URL, decode_responses=True)


QUEUE_KEY = "ai:jobs"          # Redis List
DEAD_KEY = "ai:jobs:dead"      # Redis List (dead-letter)


# -------------------------
# Auth
# -------------------------
def _auth_or_401(request) -> Optional[JsonResponse]:
    token = request.headers.get("X-Worker-Token")
    if not token or token != getattr(settings, "INTERNAL_WORKER_TOKEN", None):
        return JsonResponse({"detail": "unauthorized"}, status=401)
    return None


def _queue_backend() -> str:
    """
    기본은 DB (운영 정석)
    필요 시 settings.AI_QUEUE_BACKEND="redis"로 legacy 사용 가능
    """
    return str(getattr(settings, "AI_QUEUE_BACKEND", "db")).lower().strip() or "db"


# -------------------------
# GET /api/v1/internal/ai/job/next/
# -------------------------
@csrf_exempt
@require_http_methods(["GET"])
def next_ai_job_view(request):
    unauth = _auth_or_401(request)
    if unauth:
        return unauth

    backend = _queue_backend()

    # ==================================================
    # ✅ 운영 기본: DBQueue claim (SQS 스타일 lease)
    # ==================================================
    if backend == "db":
        worker_id = request.headers.get("X-Worker-Id") or request.META.get("REMOTE_ADDR") or "worker"
        q = DBJobQueue()
        claimed = q.claim(worker_id=str(worker_id))
        if not claimed:
            return JsonResponse({"job": None}, status=200)

        job = AIJob.new(
            type=claimed.job_type,
            payload=claimed.payload,
            tenant_id=claimed.tenant_id,
            source_domain=claimed.source_domain,
            source_id=claimed.source_id,
        )
        # ✅ contracts 고정: job.id를 claimed.job_id로 덮어써야 하지만 AIJob.new는 새 UUID 생성 가능성.
        # 그래서 from_dict로 강제 구성: AIJob의 실제 구조는 contracts에 따르며, 여기서는 dict 기반으로 안정화.
        # (contracts 수정 금지 조건 충족)
        try:
            job = AIJob.from_dict({
                "id": claimed.job_id,
                "type": claimed.job_type,
                "payload": claimed.payload,
                "tenant_id": claimed.tenant_id,
                "source_domain": claimed.source_domain,
                "source_id": claimed.source_id,
            })
        except Exception:
            # 최후 방어: 최소 필드만 반환
            return JsonResponse({"job": {"id": claimed.job_id, "type": claimed.job_type, "payload": claimed.payload}}, status=200)

        return JsonResponse({"job": job.to_dict()}, status=200)

    # ==================================================
    # Legacy: Redis pop (삭제 금지)
    # ==================================================
    r = _redis()
    raw = r.rpop(QUEUE_KEY)
    if not raw:
        return JsonResponse({"job": None}, status=200)

    try:
        job = AIJob.from_json(raw)
        return JsonResponse({"job": job.to_dict()}, status=200)

    except Exception:
        logger.exception("AIJob parsing failed. Moving to dead-letter.")
        r.lpush(DEAD_KEY, raw)
        return JsonResponse({"job": None}, status=200)


# -------------------------
# POST /api/v1/internal/ai/job/result/
# -------------------------
@csrf_exempt
@require_http_methods(["POST"])
def submit_ai_result_view(request):
    """
    Worker → API 콜백 (운영 정석)
    - job_id 기반 idempotent
    - submission_id는 선택(optional)로만 처리
    - 결과 중복 제출 방지: ai_result one-to-one 기반 업서트
    """
    unauth = _auth_or_401(request)
    if unauth:
        return unauth

    try:
        body = json.loads(request.body.decode("utf-8"))
    except Exception:
        return JsonResponse({"detail": "invalid json"}, status=400)

    job_id = body.get("job_id")
    submission_id = body.get("submission_id")  # legacy/optional
    status = str(body.get("status") or "DONE").upper()
    result = body.get("result") if isinstance(body.get("result"), dict) else None
    error = body.get("error")
    error_str = str(error) if error else ""

    # ✅ 최소 요구: job_id (정석)
    if not job_id:
        # 호환: submission_id만 온 경우(구형 워커), job row에서 source_id 매칭 시도
        if submission_id:
            job = AIJobModel.objects.filter(source_id=str(submission_id)).order_by("-created_at").first()
            if job:
                job_id = job.job_id
        if not job_id:
            return JsonResponse({"detail": "job_id required"}, status=400)

    job = AIJobModel.objects.filter(job_id=str(job_id)).first()
    if not job:
        return JsonResponse({"detail": "job not found"}, status=404)

    # ==================================================
    # ✅ idempotent: 이미 결과가 저장돼 있으면 그대로 OK
    # ==================================================
    existing = AIResultModel.objects.filter(job=job).first()
    if existing:
        # 상태만 보정(이미 DONE인데 다시 FAILED 같은 건 무시)
        return JsonResponse({"ok": True, "detail": "duplicate_ignored"}, status=200)

    # ==================================================
    # 결과 저장 (fact)
    # ==================================================
    AIResultModel.objects.create(
        job=job,
        payload=result,
    )

    # ==================================================
    # 상태 반영 + retry 정책
    # ==================================================
    q = DBJobQueue()

    if status == "FAILED":
        # job을 retryable로 보고 backoff 스케줄링 (attempt_count/max_attempts로 제어)
        q.mark_failed(job_id=job.job_id, error=error_str or "failed", retryable=True)
        return JsonResponse({"ok": True, "detail": "failed_recorded"}, status=200)

    # DONE
    q.mark_done(job_id=job.job_id)

    # ==================================================
    # 도메인 라우팅: submission 기반 작업일 때만 적용
    # (시험지 생성/숙제 검사 등 submission_id 없는 타입도 정상 완료)
    # ==================================================
    if submission_id:
        outcome = apply_ai_result_for_submission(
            submission_id=int(submission_id),
            status="DONE",
            result=result if isinstance(result, dict) else None,
            error=None,
        )
        if outcome.returned_submission_id and outcome.should_grade:
            grade_submission_task.delay(int(outcome.returned_submission_id))

        return JsonResponse({"ok": True, "detail": outcome.detail}, status=200)

    return JsonResponse({"ok": True, "detail": "done"}, status=200)


==========================================================================================
# FILE: legacy/views_internal.py
==========================================================================================
# apps/domains/ai/views_internal.py
from django.http import JsonResponse
from django.views.decorators.http import require_GET
from django.db import transaction
from django.conf import settings

from apps.domains.ai.models import AIJobModel
from apps.shared.contracts.ai_job import AIJob


def _auth_worker(request):
    token = request.headers.get("X-Worker-Token")
    return token and token == settings.INTERNAL_WORKER_TOKEN


@require_GET
def next_ai_job(request):
    """
    Worker → API
    GET /api/v1/internal/ai/job/next/
    """
    if not _auth_worker(request):
        return JsonResponse({"detail": "unauthorized"}, status=401)

    with transaction.atomic():
        job = (
            AIJobModel.objects
            .select_for_update(skip_locked=True)
            .filter(status="PENDING")
            .order_by("created_at")
            .first()
        )

        if not job:
            return JsonResponse({"job": None})

        job.status = "RUNNING"
        job.save(update_fields=["status", "updated_at"])

    ai_job = AIJob(
        id=job.job_id,
        type=job.job_type,
        payload=job.payload,
        tenant_id=None,
        source_domain=None,
        source_id=None,
    )

    return JsonResponse({"job": ai_job.to_dict()})


==========================================================================================
# FILE: legacy/views/internal_ai_job_view.py
==========================================================================================
# apps/domains/ai/views/internal_ai_job_view.py
from __future__ import annotations

from typing import Any, Dict, Optional

from django.conf import settings
from rest_framework import status
from rest_framework.permissions import AllowAny
from rest_framework.response import Response
from rest_framework.views import APIView

from apps.shared.contracts.ai_job import AIJob as AIJobContract
from apps.domains.ai.models import AIJobModel, AIResultModel
from apps.domains.ai.queueing.db_queue import DBJobQueue


def _get_worker_token_secret() -> str:
    v = getattr(settings, "INTERNAL_WORKER_TOKEN", None)
    return str(v or "")


def _require_worker_auth(request) -> Optional[Response]:
    expected = _get_worker_token_secret()
    if not expected:
        return Response(
            {"detail": "INTERNAL_WORKER_TOKEN not configured"},
            status=status.HTTP_503_SERVICE_UNAVAILABLE,
        )

    token = request.headers.get("X-Worker-Token") or request.META.get("HTTP_X_WORKER_TOKEN") or ""
    if str(token) != str(expected):
        return Response({"detail": "Unauthorized worker"}, status=status.HTTP_401_UNAUTHORIZED)
    return None


def _worker_id(request) -> str:
    return request.headers.get("X-Worker-Id") or request.META.get("HTTP_X_WORKER_ID") or "ai-worker"


class InternalAIJobNextView(APIView):
    """
    GET /api/v1/internal/ai/job/next/
    response: { "job": {...} | null }
    """

    permission_classes = [AllowAny]

    def get(self, request):
        auth = _require_worker_auth(request)
        if auth:
            return auth

        q = DBJobQueue()
        claimed = q.claim(worker_id=_worker_id(request))
        if not claimed:
            return Response({"job": None}, status=status.HTTP_200_OK)

        # contracts 고정: id는 job_id(문자열 UUID)
        job = AIJobContract.from_dict(
            {
                "id": claimed.job_id,
                "type": claimed.job_type,
                "payload": claimed.payload,
                "tenant_id": claimed.tenant_id,
                "source_domain": claimed.source_domain,
                "source_id": claimed.source_id,
            }
        )
        return Response({"job": job.to_dict()}, status=status.HTTP_200_OK)


class InternalAIJobResultView(APIView):
    """
    POST /api/v1/internal/ai/job/result/
    payload:
      {
        "job_id": "...",
        "submission_id": 123,      # optional legacy
        "status": "DONE|FAILED",
        "result": {...} | null,
        "error": "..." | null
      }
    """

    permission_classes = [AllowAny]

    def post(self, request):
        auth = _require_worker_auth(request)
        if auth:
            return auth

        data: Dict[str, Any] = request.data if isinstance(request.data, dict) else {}

        job_id = data.get("job_id")
        if not job_id:
            return Response({"detail": "job_id required"}, status=status.HTTP_400_BAD_REQUEST)

        status_in = str(data.get("status") or "DONE").upper().strip()
        if status_in not in ("DONE", "FAILED"):
            return Response({"detail": "status must be DONE or FAILED"}, status=status.HTTP_400_BAD_REQUEST)

        result = data.get("result")
        if result is not None and not isinstance(result, dict):
            return Response({"detail": "result must be object or null"}, status=status.HTTP_400_BAD_REQUEST)

        error = str(data.get("error") or "")

        job = AIJobModel.objects.filter(job_id=str(job_id)).first()
        if not job:
            return Response({"detail": "job not found"}, status=status.HTTP_404_NOT_FOUND)

        # idempotent: if result already stored, ignore duplicates
        if AIResultModel.objects.filter(job=job).exists():
            return Response({"ok": True, "detail": "duplicate_ignored"}, status=status.HTTP_200_OK)

        # store fact
        AIResultModel.objects.create(job=job, payload=(result or None))

        q = DBJobQueue()
        if status_in == "FAILED":
            q.mark_failed(job_id=job.job_id, error=error or "failed", retryable=True)
            return Response({"ok": True, "detail": "failed_recorded"}, status=status.HTTP_200_OK)

        q.mark_done(job_id=job.job_id)
        return Response({"ok": True, "detail": "done"}, status=status.HTTP_200_OK)


==========================================================================================
# FILE: migrations/0001_initial.py
==========================================================================================
# Generated by Django 5.2.9 on 2026-01-06 02:52

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = []

    operations = [
        migrations.CreateModel(
            name="AIJobModel",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("updated_at", models.DateTimeField(auto_now=True)),
                ("job_id", models.CharField(max_length=64, unique=True)),
                ("job_type", models.CharField(max_length=50)),
                (
                    "status",
                    models.CharField(
                        choices=[
                            ("PENDING", "PENDING"),
                            ("RUNNING", "RUNNING"),
                            ("DONE", "DONE"),
                            ("FAILED", "FAILED"),
                        ],
                        default="PENDING",
                        max_length=20,
                    ),
                ),
                ("payload", models.JSONField()),
                ("error_message", models.TextField(blank=True)),
            ],
            options={
                "db_table": "ai_job",
            },
        ),
        migrations.CreateModel(
            name="AIResultModel",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("updated_at", models.DateTimeField(auto_now=True)),
                ("payload", models.JSONField(blank=True, null=True)),
                (
                    "job",
                    models.OneToOneField(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="result",
                        to="ai_domain.aijobmodel",
                    ),
                ),
            ],
            options={
                "db_table": "ai_result",
            },
        ),
    ]


==========================================================================================
# FILE: migrations/0002_job_queue_fields.py
==========================================================================================
# Generated by Django 5.2.x on 2026-01-31
from django.db import migrations, models
import django.utils.timezone


class Migration(migrations.Migration):

    dependencies = [
        ("ai_domain", "0001_initial"),
    ]

    operations = [
        migrations.AddField(
            model_name="aijobmodel",
            name="tenant_id",
            field=models.CharField(blank=True, max_length=64, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="source_domain",
            field=models.CharField(blank=True, max_length=64, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="source_id",
            field=models.CharField(blank=True, max_length=64, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="attempt_count",
            field=models.IntegerField(default=0),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="max_attempts",
            field=models.IntegerField(default=5),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="locked_by",
            field=models.CharField(blank=True, max_length=128, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="locked_at",
            field=models.DateTimeField(blank=True, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="lease_expires_at",
            field=models.DateTimeField(blank=True, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="last_heartbeat_at",
            field=models.DateTimeField(blank=True, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="next_run_at",
            field=models.DateTimeField(default=django.utils.timezone.now),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="last_error",
            field=models.TextField(blank=True, default=""),
        ),
        migrations.AddIndex(
            model_name="aijobmodel",
            index=models.Index(fields=["status", "next_run_at"], name="ai_job_status_next_run_idx"),
        ),
        migrations.AddIndex(
            model_name="aijobmodel",
            index=models.Index(fields=["lease_expires_at"], name="ai_job_lease_idx"),
        ),
        migrations.AddIndex(
            model_name="aijobmodel",
            index=models.Index(fields=["source_domain", "source_id"], name="ai_job_source_idx"),
        ),
    ]


==========================================================================================
# FILE: migrations/0003_alter_aijobmodel_status_and_more.py
==========================================================================================
# Generated by Django 5.2.9 on 2026-01-31 02:51

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("ai_domain", "0002_job_queue_fields"),
    ]

    operations = [
        migrations.AlterField(
            model_name="aijobmodel",
            name="status",
            field=models.CharField(
                choices=[
                    ("PENDING", "PENDING"),
                    ("RUNNING", "RUNNING"),
                    ("DONE", "DONE"),
                    ("FAILED", "FAILED"),
                ],
                db_index=True,
                default="PENDING",
                max_length=20,
            ),
        ),
        migrations.AddIndex(
            model_name="aijobmodel",
            index=models.Index(
                fields=["status", "created_at"], name="ai_job_status_ba4967_idx"
            ),
        ),
        migrations.AddIndex(
            model_name="aijobmodel",
            index=models.Index(fields=["locked_at"], name="ai_job_locked__f6f4a2_idx"),
        ),
    ]


==========================================================================================
# FILE: migrations/0004_remove_aijobmodel_ai_job_status_ba4967_idx_and_more.py
==========================================================================================
# Generated by Django 5.2.9 on 2026-01-31 03:56

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("ai_domain", "0003_alter_aijobmodel_status_and_more"),
    ]

    operations = [
        migrations.RemoveIndex(
            model_name="aijobmodel",
            name="ai_job_status_ba4967_idx",
        ),
        migrations.RemoveIndex(
            model_name="aijobmodel",
            name="ai_job_locked__f6f4a2_idx",
        ),
        migrations.AlterField(
            model_name="aijobmodel",
            name="status",
            field=models.CharField(
                choices=[
                    ("PENDING", "PENDING"),
                    ("RUNNING", "RUNNING"),
                    ("DONE", "DONE"),
                    ("FAILED", "FAILED"),
                ],
                default="PENDING",
                max_length=20,
            ),
        ),
    ]


==========================================================================================
# FILE: migrations/0005_alter_aijobmodel_error_message_and_more.py
==========================================================================================
# Generated by Django 5.2.9 on 2026-01-31 14:51

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("ai_domain", "0004_remove_aijobmodel_ai_job_status_ba4967_idx_and_more"),
    ]

    operations = [
        migrations.AlterField(
            model_name="aijobmodel",
            name="error_message",
            field=models.TextField(blank=True, default=""),
        ),
        migrations.AlterField(
            model_name="aijobmodel",
            name="payload",
            field=models.JSONField(blank=True, default=dict),
        ),
    ]


==========================================================================================
# FILE: migrations/__init__.py
==========================================================================================



==========================================================================================
# FILE: queueing/__init__.py
==========================================================================================
# apps/domains/ai/queueing/__init__.py


==========================================================================================
# FILE: queueing/db_queue.py
==========================================================================================
# apps/domains/ai/queueing/db_queue.py
from __future__ import annotations

from dataclasses import dataclass
from datetime import timedelta
from typing import Optional

from django.db import transaction
from django.utils import timezone

from apps.domains.ai.models import AIJobModel
from apps.domains.ai.queueing.interfaces import JobQueue, ClaimedJob


@dataclass(frozen=True)
class DBQueueConfig:
    visibility_timeout_sec: int = 120  # lease duration
    default_max_attempts: int = 5
    base_backoff_sec: int = 2
    max_backoff_sec: int = 120


class DBJobQueue(JobQueue):
    """
    SQS-style lease/visibility timeout on DB.
    - DB is SSOT
    - Worker is stateless
    - Crash recovery via lease expiry
    """

    def __init__(self, cfg: Optional[DBQueueConfig] = None):
        self.cfg = cfg or DBQueueConfig()

    def publish(self, *, job_id: str) -> None:
        now = timezone.now()
        AIJobModel.objects.filter(job_id=job_id).update(
            status="PENDING",
            next_run_at=now,
        )

    @transaction.atomic
    def claim(self, *, worker_id: str) -> Optional[ClaimedJob]:
        now = timezone.now()

        # 0) reclaim stale RUNNING jobs
        AIJobModel.objects.select_for_update().filter(
            status="RUNNING",
            lease_expires_at__isnull=False,
            lease_expires_at__lt=now,
        ).update(
            status="PENDING",
            locked_by=None,
            locked_at=None,
            lease_expires_at=None,
        )

        # 1) pick next runnable
        qs = (
            AIJobModel.objects.select_for_update(skip_locked=True)
            .filter(status="PENDING", next_run_at__lte=now)
            .order_by("next_run_at", "created_at")
        )

        job = qs.first()
        if not job:
            return None

        # 2) attempts + lease
        attempt = int(job.attempt_count or 0) + 1
        max_attempts = int(job.max_attempts or self.cfg.default_max_attempts)
        if attempt > max_attempts:
            job.status = "FAILED"
            job.error_message = job.error_message or "max_attempts_exceeded"
            job.last_error = job.last_error or "max_attempts_exceeded"
            job.save(update_fields=["status", "error_message", "last_error", "updated_at"])
            return None

        lease_expires = now + timedelta(seconds=self.cfg.visibility_timeout_sec)
        job.status = "RUNNING"
        job.attempt_count = attempt
        job.max_attempts = max_attempts
        job.locked_by = str(worker_id)
        job.locked_at = now
        job.lease_expires_at = lease_expires
        job.last_heartbeat_at = now
        job.save(
            update_fields=[
                "status",
                "attempt_count",
                "max_attempts",
                "locked_by",
                "locked_at",
                "lease_expires_at",
                "last_heartbeat_at",
                "updated_at",
            ]
        )

        return ClaimedJob(
            job_id=job.job_id,
            job_type=job.job_type,
            payload=job.payload or {},
            tenant_id=job.tenant_id,
            source_domain=job.source_domain,
            source_id=job.source_id,
            locked_by=job.locked_by,
        )

    def heartbeat(self, *, job_id: str, worker_id: str) -> None:
        now = timezone.now()
        AIJobModel.objects.filter(job_id=job_id, locked_by=str(worker_id), status="RUNNING").update(
            last_heartbeat_at=now,
            updated_at=now,
        )

    def mark_done(self, *, job_id: str) -> None:
        AIJobModel.objects.filter(job_id=job_id).update(
            status="DONE",
            error_message="",
            updated_at=timezone.now(),
        )

    def mark_failed(self, *, job_id: str, error: str, retryable: bool = True) -> None:
        """
        실패 처리 + retry/backoff
        - retryable=True & attempt_count < max_attempts => PENDING with next_run_at(backoff)
        - else => FAILED
        """
        now = timezone.now()
        job = AIJobModel.objects.filter(job_id=job_id).first()
        if not job:
            return

        attempt = int(job.attempt_count or 0)
        max_attempts = int(job.max_attempts or self.cfg.default_max_attempts)

        backoff = min(self.cfg.max_backoff_sec, (2 ** max(0, attempt - 1)) * self.cfg.base_backoff_sec)
        next_run = now + timedelta(seconds=int(backoff))

        err = str(error or "")[:5000]

        if retryable and attempt < max_attempts:
            AIJobModel.objects.filter(job_id=job_id).update(
                status="PENDING",
                last_error=err,
                error_message=err,
                next_run_at=next_run,
                locked_by=None,
                locked_at=None,
                lease_expires_at=None,
                updated_at=now,
            )
            return

        AIJobModel.objects.filter(job_id=job_id).update(
            status="FAILED",
            last_error=err,
            error_message=err,
            locked_by=None,
            locked_at=None,
            lease_expires_at=None,
            updated_at=now,
        )


==========================================================================================
# FILE: queueing/interfaces.py
==========================================================================================
# apps/domains/ai/queueing/interfaces.py
from __future__ import annotations

from dataclasses import dataclass
from typing import Optional, Protocol, Dict, Any


@dataclass(frozen=True)
class ClaimedJob:
    job_id: str
    job_type: str
    payload: Dict[str, Any]
    tenant_id: Optional[str] = None
    source_domain: Optional[str] = None
    source_id: Optional[str] = None

    # lease/debug
    locked_by: Optional[str] = None


class JobQueue(Protocol):
    def publish(self, *, job_id: str) -> None:
        ...

    def claim(self, *, worker_id: str) -> Optional[ClaimedJob]:
        ...

    def heartbeat(self, *, job_id: str, worker_id: str) -> None:
        ...

    def mark_done(self, *, job_id: str) -> None:
        ...

    def mark_failed(self, *, job_id: str, error: str, retryable: bool = True) -> None:
        ...


==========================================================================================
# FILE: queueing/publisher.py
==========================================================================================
# apps/domains/ai/queueing/publisher.py
from __future__ import annotations

from apps.shared.contracts.ai_job import AIJob
from apps.domains.ai.queueing.db_queue import DBJobQueue


def publish_ai_job_db(job: AIJob) -> None:
    """
    DBQueue 발행 (운영 기본)

    - gateway에서 AIJobModel row를 선생성하고,
      여기서는 DBJobQueue.publish 로 "PENDING + next_run_at"만 세팅한다.
    - DB가 SSOT(단일진실)이며, 워커는 /internal endpoint로 pull 한다.
    """
    q = DBJobQueue()
    q.publish(job_id=str(job.id))


# ----------------------------------------------------------------------
# Backward-compat export (SSOT)
# gateway.py 등에서 publish_job 이름을 기대하는 경우가 많아 alias로 봉인한다.
# ----------------------------------------------------------------------
def publish_job(job: AIJob) -> None:
    """
    Public publisher entrypoint (SSOT).
    Keep this name stable to avoid import breaks.
    """
    publish_ai_job_db(job)


==========================================================================================
# FILE: services/worker_instance_control.py
==========================================================================================
# PATH: apps/domains/ai/services/worker_instance_control.py

import boto3
import logging

logger = logging.getLogger(__name__)

REGION = "ap-northeast-2"
AI_WORKER_INSTANCE_ID = "i-0f52f9d89481385a8"  # 네 실제 워커 EC2

def start_ai_worker_instance():
    """
    API 서버에서 호출
    - AI 워커 EC2를 켜기만 함
    - stop은 절대 여기서 하지 않음
    """
    ec2 = boto3.client("ec2", region_name=REGION)

    logger.info("[AI] Starting AI worker EC2 instance")

    ec2.start_instances(
        InstanceIds=[AI_WORKER_INSTANCE_ID]
    )


==========================================================================================
# FILE: views/__init__.py
==========================================================================================
# PATH: apps/domains/ai/views/__init__.py
# empty


==========================================================================================
# FILE: views/exam_sheet.py
==========================================================================================
# PATH: apps/domains/exams/models/exam_sheet.py
from django.db import models


class ExamSheet(models.Model):
    """
    시험(exam)에서 사용하는 시험지(sheet)
    - 시험 실행 시 단일 진실
    """

    exam_id = models.PositiveIntegerField(db_index=True)
    sheet_id = models.PositiveIntegerField(db_index=True)

    class Meta:
        db_table = "exams_exam_sheet"
        unique_together = ("exam_id", "sheet_id")


==========================================================================================
# FILE: views/internal_ai_job_view.py
==========================================================================================
# PATH: apps/domains/ai/views/internal_ai_job_view.py
from __future__ import annotations

from typing import Any, Dict, Optional

from django.conf import settings
from rest_framework import status
from rest_framework.permissions import AllowAny
from rest_framework.response import Response
from rest_framework.views import APIView

from apps.shared.contracts.ai_job import AIJob as AIJobContract
from apps.domains.ai.models import AIJobModel, AIResultModel
from apps.domains.ai.queueing.db_queue import DBJobQueue


def _get_worker_token_secret() -> str:
    v = getattr(settings, "INTERNAL_WORKER_TOKEN", None)
    return str(v or "")


def _require_worker_auth(request) -> Optional[Response]:
    expected = _get_worker_token_secret()
    if not expected:
        return Response(
            {"detail": "INTERNAL_WORKER_TOKEN not configured"},
            status=status.HTTP_503_SERVICE_UNAVAILABLE,
        )

    token = request.headers.get("X-Worker-Token") or request.META.get("HTTP_X_WORKER_TOKEN") or ""
    if str(token) != str(expected):
        return Response({"detail": "Unauthorized worker"}, status=status.HTTP_401_UNAUTHORIZED)
    return None


def _worker_id(request) -> str:
    return request.headers.get("X-Worker-Id") or request.META.get("HTTP_X_WORKER_ID") or "ai-worker"


class InternalAIJobNextView(APIView):
    """
    GET /api/v1/internal/ai/job/next/
    response: { "job": {...} | null }
    """

    permission_classes = [AllowAny]

    def get(self, request):
        auth = _require_worker_auth(request)
        if auth:
            return auth

        q = DBJobQueue()
        claimed = q.claim(worker_id=_worker_id(request))
        if not claimed:
            return Response({"job": None}, status=status.HTTP_200_OK)

        job = AIJobContract.from_dict(
            {
                "id": claimed.job_id,
                "type": claimed.job_type,
                "payload": claimed.payload,
                "tenant_id": claimed.tenant_id,
                "source_domain": claimed.source_domain,
                "source_id": claimed.source_id,
            }
        )
        return Response({"job": job.to_dict()}, status=status.HTTP_200_OK)


class InternalAIJobResultView(APIView):
    """
    POST /api/v1/internal/ai/job/result/
    payload:
      {
        "job_id": "...",
        "submission_id": 123,      # optional legacy
        "status": "DONE|FAILED",
        "result": {...} | null,
        "error": "..." | null
      }
    """

    permission_classes = [AllowAny]

    def post(self, request):
        auth = _require_worker_auth(request)
        if auth:
            return auth

        data: Dict[str, Any] = request.data if isinstance(request.data, dict) else {}

        job_id = data.get("job_id")
        if not job_id:
            return Response({"detail": "job_id required"}, status=status.HTTP_400_BAD_REQUEST)

        status_in = str(data.get("status") or "DONE").upper().strip()
        if status_in not in ("DONE", "FAILED"):
            return Response({"detail": "status must be DONE or FAILED"}, status=status.HTTP_400_BAD_REQUEST)

        result = data.get("result")
        if result is not None and not isinstance(result, dict):
            return Response({"detail": "result must be object or null"}, status=status.HTTP_400_BAD_REQUEST)

        error = str(data.get("error") or "")

        job = AIJobModel.objects.filter(job_id=str(job_id)).first()
        if not job:
            return Response({"detail": "job not found"}, status=status.HTTP_404_NOT_FOUND)

        # idempotent: if result already stored, ignore duplicates
        if AIResultModel.objects.filter(job=job).exists():
            return Response({"ok": True, "detail": "duplicate_ignored"}, status=status.HTTP_200_OK)

        # store fact
        AIResultModel.objects.create(job=job, payload=(result or None))

        q = DBJobQueue()
        if status_in == "FAILED":
            q.mark_failed(job_id=job.job_id, error=error or "failed", retryable=True)
            return Response({"ok": True, "detail": "failed_recorded"}, status=status.HTTP_200_OK)

        q.mark_done(job_id=job.job_id)
        return Response({"ok": True, "detail": "done"}, status=status.HTTP_200_OK)
