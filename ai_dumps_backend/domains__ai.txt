====================================================================================================
# BACKEND APP: domains__ai
# ROOT PATH: C:\academy\apps\domains\ai
====================================================================================================


==========================================================================================
# FILE: __init__.py
==========================================================================================
# apps/domains/ai/__init__.py


==========================================================================================
# FILE: apps.py
==========================================================================================
# apps/domains/ai/apps.py
from django.apps import AppConfig


class AIDomainConfig(AppConfig):
    default_auto_field = "django.db.models.BigAutoField"
    name = "apps.domains.ai"
    label = "ai_domain"


==========================================================================================
# FILE: callbacks.py
==========================================================================================
# apps/domains/ai/callbacks.py
from apps.shared.contracts.ai_result import AIResult
from apps.domains.ai.models import AIJobModel
from apps.domains.submissions.services.ai_omr_result_mapper import apply_ai_result
from apps.domains.results.tasks.grading_tasks import grade_submission_task


def handle_ai_result(result: AIResult) -> None:
    """
    Worker → API callback entry

    규칙(무퇴화/정규화):
    - 상태(status) 변경은 Queue/API(InternalAIJobResultView + DBJobQueue)가 SSOT로 처리한다.
    - callbacks는 "도메인 후속 처리"만 담당한다.
    - 결과 fact(AIResultModel)는 API 계층에서 이미 저장되므로 여기서 생성/수정하지 않는다.
    """
    # callbacks가 job 존재를 전제로 동작 (gateway에서 job row를 선생성)
    AIJobModel.objects.get(job_id=result.job_id)

    if result.status == "FAILED":
        # 실패 상태/에러/재시도는 API + DBJobQueue에서 처리됨
        return

    # DONE: submissions 로 위임 (답안 중간산물 저장)
    payload = result.result if isinstance(result.result, dict) else {}
    submission_id = apply_ai_result(payload)

    # 채점 job enqueue (results 책임)
    if submission_id:
        grade_submission_task.delay(int(submission_id))


==========================================================================================
# FILE: gateway.py
==========================================================================================
from __future__ import annotations

from typing import Any, Dict, Optional

from apps.shared.contracts.ai_job import AIJob
from apps.domains.ai.types import ensure_payload_dict, AIJobType
from apps.domains.ai.safe import safe_dispatch
from apps.domains.ai.queueing.publisher import publish_job
from apps.domains.ai.models import AIJobModel


def dispatch_job(
    *,
    job_type: AIJobType,
    payload: Dict[str, Any],
    tenant_id: Optional[str] = None,
    source_domain: Optional[str] = None,
    source_id: Optional[str] = None,
) -> Dict[str, Any]:
    payload = ensure_payload_dict(payload)

    job = AIJob.new(
        type=job_type,
        payload=payload,
        tenant_id=tenant_id,
        source_domain=source_domain,
        source_id=source_id,
    )

    def _do():
        # ✅ callbacks가 AIJobModel을 조회하므로, 발행 시점에 반드시 저장
        job_model = AIJobModel.objects.create(
            job_id=job.id,
            job_type=job.type,
            payload=job.payload,
            status="PENDING",
            tenant_id=tenant_id,
            source_domain=source_domain,
            source_id=source_id,
        )

        try:
            publish_job(job)
        except Exception as e:
            job_model.status = "FAILED"
            job_model.error_message = str(e)
            job_model.last_error = str(e)
            job_model.save(update_fields=["status", "error_message", "last_error", "updated_at"])
            raise

        return {"ok": True, "job_id": job.id, "type": job.type}

    return safe_dispatch(_do, fallback={"ok": False, "job_id": job.id, "type": job.type})


==========================================================================================
# FILE: models.py
==========================================================================================
# apps/domains/ai/models.py
from __future__ import annotations

from django.db import models
from django.utils import timezone

from apps.api.common.models import BaseModel


class AIJobModel(BaseModel):
    """
    AI Job Meta (DB is SSOT)
    - API server owns lifecycle
    - Worker pulls via internal endpoints
    """

    job_id = models.CharField(max_length=64, unique=True)
    job_type = models.CharField(max_length=50)

    status = models.CharField(
        max_length=20,
        choices=[
            ("PENDING", "PENDING"),
            ("RUNNING", "RUNNING"),
            ("DONE", "DONE"),
            ("FAILED", "FAILED"),
        ],
        default="PENDING",
    )

    payload = models.JSONField(default=dict, blank=True)
    error_message = models.TextField(blank=True, default="")

    # ---- routing / trace ----
    tenant_id = models.CharField(max_length=64, null=True, blank=True)
    source_domain = models.CharField(max_length=64, null=True, blank=True)
    source_id = models.CharField(max_length=64, null=True, blank=True)

    # ---- retry / lease ----
    attempt_count = models.IntegerField(default=0)
    max_attempts = models.IntegerField(default=5)

    locked_by = models.CharField(max_length=128, null=True, blank=True)
    locked_at = models.DateTimeField(null=True, blank=True)
    lease_expires_at = models.DateTimeField(null=True, blank=True)
    last_heartbeat_at = models.DateTimeField(null=True, blank=True)

    next_run_at = models.DateTimeField(default=timezone.now)
    last_error = models.TextField(blank=True, default="")

    class Meta:
        db_table = "ai_job"
        indexes = [
            models.Index(fields=["status", "next_run_at"], name="ai_job_status_next_run_idx"),
            models.Index(fields=["lease_expires_at"], name="ai_job_lease_idx"),
            models.Index(fields=["source_domain", "source_id"], name="ai_job_source_idx"),
        ]

    def __str__(self) -> str:
        return f"AIJobModel<{self.job_id}>({self.job_type})[{self.status}]"


class AIResultModel(BaseModel):
    """
    AI Result Fact (write-once, idempotency anchor)
    - OneToOne to enforce single fact row per job
    """

    job = models.OneToOneField(
        AIJobModel,
        on_delete=models.CASCADE,
        related_name="result",
    )
    payload = models.JSONField(null=True, blank=True)

    class Meta:
        db_table = "ai_result"

    def __str__(self) -> str:
        return f"AIResultModel(job_id={self.job_id})"


==========================================================================================
# FILE: safe.py
==========================================================================================
# apps/domains/ai/safe.py
from __future__ import annotations

import logging
from typing import Any, Dict, Optional

logger = logging.getLogger(__name__)


def safe_dispatch(fn, *, fallback: Optional[Dict[str, Any]] = None, **kwargs) -> Dict[str, Any]:
    """
    AI Job 발행을 안전하게 감싼다.
    API는 실패해도 깨지면 안 된다.
    """
    try:
        return fn(**kwargs)
    except Exception as e:
        logger.exception("AI job dispatch failed", exc_info=e)
        return fallback or {"ok": False, "error": str(e)}


==========================================================================================
# FILE: types.py
==========================================================================================
from __future__ import annotations

from typing import Any, Dict, Literal, Optional, TypedDict


AIJobType = Literal[
    "ocr",
    "question_segmentation",
    "handwriting_analysis",
    "embedding",
    "problem_generation",
    "homework_video_analysis",
]


class OCRPayload(TypedDict, total=False):
    image_path: str
    engine: Optional[Literal["google", "tesseract", "auto"]]
    academy_id: Optional[int]


class SegmentationPayload(TypedDict, total=False):
    image_path: str
    engine: Optional[Literal["yolo", "opencv", "template", "auto"]]


class HandwritingPayload(TypedDict, total=False):
    image_path: str


class EmbeddingPayload(TypedDict, total=False):
    texts: list[str]
    backend: Optional[Literal["local", "openai", "auto"]]


class ProblemGenerationPayload(TypedDict, total=False):
    ocr_text: str
    model: Optional[str]


class HomeworkVideoPayload(TypedDict, total=False):
    video_path: str
    frame_stride: Optional[int]
    min_frame_count: Optional[int]


def ensure_payload_dict(payload: Any) -> Dict[str, Any]:
    if payload is None:
        return {}
    if isinstance(payload, dict):
        return payload
    raise TypeError("payload must be a dict")


==========================================================================================
# FILE: urls.py
==========================================================================================
# PATH: apps/domains/ai/urls.py
from django.urls import path

from apps.domains.ai.views.internal_ai_job_view import (
    InternalAIJobNextView,
    InternalAIJobResultView,
)

urlpatterns = [
    path("job/next/", InternalAIJobNextView.as_view(), name="internal-ai-job-next"),
    path("job/result/", InternalAIJobResultView.as_view(), name="internal-ai-job-result"),
]


==========================================================================================
# FILE: migrations/0001_initial.py
==========================================================================================
# Generated by Django 5.2.9 on 2026-01-06 02:52

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = []

    operations = [
        migrations.CreateModel(
            name="AIJobModel",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("updated_at", models.DateTimeField(auto_now=True)),
                ("job_id", models.CharField(max_length=64, unique=True)),
                ("job_type", models.CharField(max_length=50)),
                (
                    "status",
                    models.CharField(
                        choices=[
                            ("PENDING", "PENDING"),
                            ("RUNNING", "RUNNING"),
                            ("DONE", "DONE"),
                            ("FAILED", "FAILED"),
                        ],
                        default="PENDING",
                        max_length=20,
                    ),
                ),
                ("payload", models.JSONField()),
                ("error_message", models.TextField(blank=True)),
            ],
            options={
                "db_table": "ai_job",
            },
        ),
        migrations.CreateModel(
            name="AIResultModel",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("updated_at", models.DateTimeField(auto_now=True)),
                ("payload", models.JSONField(blank=True, null=True)),
                (
                    "job",
                    models.OneToOneField(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="result",
                        to="ai_domain.aijobmodel",
                    ),
                ),
            ],
            options={
                "db_table": "ai_result",
            },
        ),
    ]


==========================================================================================
# FILE: migrations/0002_job_queue_fields.py
==========================================================================================
# Generated by Django 5.2.x on 2026-01-31
from django.db import migrations, models
import django.utils.timezone


class Migration(migrations.Migration):

    dependencies = [
        ("ai_domain", "0001_initial"),
    ]

    operations = [
        migrations.AddField(
            model_name="aijobmodel",
            name="tenant_id",
            field=models.CharField(blank=True, max_length=64, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="source_domain",
            field=models.CharField(blank=True, max_length=64, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="source_id",
            field=models.CharField(blank=True, max_length=64, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="attempt_count",
            field=models.IntegerField(default=0),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="max_attempts",
            field=models.IntegerField(default=5),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="locked_by",
            field=models.CharField(blank=True, max_length=128, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="locked_at",
            field=models.DateTimeField(blank=True, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="lease_expires_at",
            field=models.DateTimeField(blank=True, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="last_heartbeat_at",
            field=models.DateTimeField(blank=True, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="next_run_at",
            field=models.DateTimeField(default=django.utils.timezone.now),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="last_error",
            field=models.TextField(blank=True, default=""),
        ),
        migrations.AddIndex(
            model_name="aijobmodel",
            index=models.Index(fields=["status", "next_run_at"], name="ai_job_status_next_run_idx"),
        ),
        migrations.AddIndex(
            model_name="aijobmodel",
            index=models.Index(fields=["lease_expires_at"], name="ai_job_lease_idx"),
        ),
        migrations.AddIndex(
            model_name="aijobmodel",
            index=models.Index(fields=["source_domain", "source_id"], name="ai_job_source_idx"),
        ),
    ]


==========================================================================================
# FILE: migrations/0003_alter_aijobmodel_status_and_more.py
==========================================================================================
# Generated by Django 5.2.9 on 2026-01-31 02:51

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("ai_domain", "0002_job_queue_fields"),
    ]

    operations = [
        migrations.AlterField(
            model_name="aijobmodel",
            name="status",
            field=models.CharField(
                choices=[
                    ("PENDING", "PENDING"),
                    ("RUNNING", "RUNNING"),
                    ("DONE", "DONE"),
                    ("FAILED", "FAILED"),
                ],
                db_index=True,
                default="PENDING",
                max_length=20,
            ),
        ),
        migrations.AddIndex(
            model_name="aijobmodel",
            index=models.Index(
                fields=["status", "created_at"], name="ai_job_status_ba4967_idx"
            ),
        ),
        migrations.AddIndex(
            model_name="aijobmodel",
            index=models.Index(fields=["locked_at"], name="ai_job_locked__f6f4a2_idx"),
        ),
    ]


==========================================================================================
# FILE: migrations/0004_remove_aijobmodel_ai_job_status_ba4967_idx_and_more.py
==========================================================================================
# Generated by Django 5.2.9 on 2026-01-31 03:56

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("ai_domain", "0003_alter_aijobmodel_status_and_more"),
    ]

    operations = [
        migrations.RemoveIndex(
            model_name="aijobmodel",
            name="ai_job_status_ba4967_idx",
        ),
        migrations.RemoveIndex(
            model_name="aijobmodel",
            name="ai_job_locked__f6f4a2_idx",
        ),
        migrations.AlterField(
            model_name="aijobmodel",
            name="status",
            field=models.CharField(
                choices=[
                    ("PENDING", "PENDING"),
                    ("RUNNING", "RUNNING"),
                    ("DONE", "DONE"),
                    ("FAILED", "FAILED"),
                ],
                default="PENDING",
                max_length=20,
            ),
        ),
    ]


==========================================================================================
# FILE: migrations/0005_alter_aijobmodel_error_message_and_more.py
==========================================================================================
# Generated by Django 5.2.9 on 2026-01-31 14:51

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("ai_domain", "0004_remove_aijobmodel_ai_job_status_ba4967_idx_and_more"),
    ]

    operations = [
        migrations.AlterField(
            model_name="aijobmodel",
            name="error_message",
            field=models.TextField(blank=True, default=""),
        ),
        migrations.AlterField(
            model_name="aijobmodel",
            name="payload",
            field=models.JSONField(blank=True, default=dict),
        ),
    ]


==========================================================================================
# FILE: migrations/__init__.py
==========================================================================================



==========================================================================================
# FILE: queueing/__init__.py
==========================================================================================
# apps/domains/ai/queueing/__init__.py


==========================================================================================
# FILE: queueing/db_queue.py
==========================================================================================
# apps/domains/ai/queueing/db_queue.py
from __future__ import annotations

from dataclasses import dataclass
from datetime import timedelta
from typing import Optional

from django.db import transaction
from django.utils import timezone

from apps.domains.ai.models import AIJobModel
from apps.domains.ai.queueing.interfaces import JobQueue, ClaimedJob


@dataclass(frozen=True)
class DBQueueConfig:
    visibility_timeout_sec: int = 120  # lease duration
    default_max_attempts: int = 5
    base_backoff_sec: int = 2
    max_backoff_sec: int = 120


class DBJobQueue(JobQueue):
    """
    SQS-style lease/visibility timeout on DB.
    - DB is SSOT
    - Worker is stateless
    - Crash recovery via lease expiry
    """

    def __init__(self, cfg: Optional[DBQueueConfig] = None):
        self.cfg = cfg or DBQueueConfig()

    def publish(self, *, job_id: str) -> None:
        now = timezone.now()
        AIJobModel.objects.filter(job_id=job_id).update(
            status="PENDING",
            next_run_at=now,
        )

    @transaction.atomic
    def claim(self, *, worker_id: str) -> Optional[ClaimedJob]:
        now = timezone.now()

        # 0) reclaim stale RUNNING jobs
        AIJobModel.objects.select_for_update().filter(
            status="RUNNING",
            lease_expires_at__isnull=False,
            lease_expires_at__lt=now,
        ).update(
            status="PENDING",
            locked_by=None,
            locked_at=None,
            lease_expires_at=None,
        )

        # 1) pick next runnable
        qs = (
            AIJobModel.objects.select_for_update(skip_locked=True)
            .filter(status="PENDING", next_run_at__lte=now)
            .order_by("next_run_at", "created_at")
        )

        job = qs.first()
        if not job:
            return None

        # 2) attempts + lease
        attempt = int(job.attempt_count or 0) + 1
        max_attempts = int(job.max_attempts or self.cfg.default_max_attempts)
        if attempt > max_attempts:
            job.status = "FAILED"
            job.error_message = job.error_message or "max_attempts_exceeded"
            job.last_error = job.last_error or "max_attempts_exceeded"
            job.save(update_fields=["status", "error_message", "last_error", "updated_at"])
            return None

        lease_expires = now + timedelta(seconds=self.cfg.visibility_timeout_sec)
        job.status = "RUNNING"
        job.attempt_count = attempt
        job.max_attempts = max_attempts
        job.locked_by = str(worker_id)
        job.locked_at = now
        job.lease_expires_at = lease_expires
        job.last_heartbeat_at = now
        job.save(
            update_fields=[
                "status",
                "attempt_count",
                "max_attempts",
                "locked_by",
                "locked_at",
                "lease_expires_at",
                "last_heartbeat_at",
                "updated_at",
            ]
        )

        return ClaimedJob(
            job_id=job.job_id,
            job_type=job.job_type,
            payload=job.payload or {},
            tenant_id=job.tenant_id,
            source_domain=job.source_domain,
            source_id=job.source_id,
            locked_by=job.locked_by,
        )

    def heartbeat(self, *, job_id: str, worker_id: str) -> None:
        now = timezone.now()
        AIJobModel.objects.filter(job_id=job_id, locked_by=str(worker_id), status="RUNNING").update(
            last_heartbeat_at=now,
            updated_at=now,
        )

    def mark_done(self, *, job_id: str) -> None:
        AIJobModel.objects.filter(job_id=job_id).update(
            status="DONE",
            error_message="",
            updated_at=timezone.now(),
        )

    def mark_failed(self, *, job_id: str, error: str, retryable: bool = True) -> None:
        """
        실패 처리 + retry/backoff
        - retryable=True & attempt_count < max_attempts => PENDING with next_run_at(backoff)
        - else => FAILED
        """
        now = timezone.now()
        job = AIJobModel.objects.filter(job_id=job_id).first()
        if not job:
            return

        attempt = int(job.attempt_count or 0)
        max_attempts = int(job.max_attempts or self.cfg.default_max_attempts)

        backoff = min(self.cfg.max_backoff_sec, (2 ** max(0, attempt - 1)) * self.cfg.base_backoff_sec)
        next_run = now + timedelta(seconds=int(backoff))

        err = str(error or "")[:5000]

        if retryable and attempt < max_attempts:
            AIJobModel.objects.filter(job_id=job_id).update(
                status="PENDING",
                last_error=err,
                error_message=err,
                next_run_at=next_run,
                locked_by=None,
                locked_at=None,
                lease_expires_at=None,
                updated_at=now,
            )
            return

        AIJobModel.objects.filter(job_id=job_id).update(
            status="FAILED",
            last_error=err,
            error_message=err,
            locked_by=None,
            locked_at=None,
            lease_expires_at=None,
            updated_at=now,
        )


==========================================================================================
# FILE: queueing/interfaces.py
==========================================================================================
# apps/domains/ai/queueing/interfaces.py
from __future__ import annotations

from dataclasses import dataclass
from typing import Optional, Protocol, Dict, Any


@dataclass(frozen=True)
class ClaimedJob:
    job_id: str
    job_type: str
    payload: Dict[str, Any]
    tenant_id: Optional[str] = None
    source_domain: Optional[str] = None
    source_id: Optional[str] = None

    # lease/debug
    locked_by: Optional[str] = None


class JobQueue(Protocol):
    def publish(self, *, job_id: str) -> None:
        ...

    def claim(self, *, worker_id: str) -> Optional[ClaimedJob]:
        ...

    def heartbeat(self, *, job_id: str, worker_id: str) -> None:
        ...

    def mark_done(self, *, job_id: str) -> None:
        ...

    def mark_failed(self, *, job_id: str, error: str, retryable: bool = True) -> None:
        ...


==========================================================================================
# FILE: queueing/publisher.py
==========================================================================================
# apps/domains/ai/queueing/publisher.py
from __future__ import annotations

from apps.shared.contracts.ai_job import AIJob
from apps.domains.ai.queueing.db_queue import DBJobQueue


def publish_ai_job_db(job: AIJob) -> None:
    """
    DBQueue 발행 (운영 기본)

    - gateway에서 AIJobModel row를 선생성하고,
      여기서는 DBJobQueue.publish 로 "PENDING + next_run_at"만 세팅한다.
    - DB가 SSOT(단일진실)이며, 워커는 /internal endpoint로 pull 한다.
    """
    q = DBJobQueue()
    q.publish(job_id=str(job.id))


# ----------------------------------------------------------------------
# Backward-compat export (SSOT)
# gateway.py 등에서 publish_job 이름을 기대하는 경우가 많아 alias로 봉인한다.
# ----------------------------------------------------------------------
def publish_job(job: AIJob) -> None:
    """
    Public publisher entrypoint (SSOT).
    Keep this name stable to avoid import breaks.
    """
    publish_ai_job_db(job)


==========================================================================================
# FILE: services/worker_instance_control.py
==========================================================================================
# PATH: apps/domains/ai/services/worker_instance_control.py

import boto3
import logging

logger = logging.getLogger(__name__)

REGION = "ap-northeast-2"
AI_WORKER_INSTANCE_ID = "i-0f52f9d89481385a8"  # 네 실제 워커 EC2

def start_ai_worker_instance():
    """
    API 서버에서 호출
    - AI 워커 EC2를 켜기만 함
    - stop은 절대 여기서 하지 않음
    """
    ec2 = boto3.client("ec2", region_name=REGION)

    logger.info("[AI] Starting AI worker EC2 instance")

    ec2.start_instances(
        InstanceIds=[AI_WORKER_INSTANCE_ID]
    )


==========================================================================================
# FILE: views/__init__.py
==========================================================================================
# PATH: apps/domains/ai/views/__init__.py
# empty


==========================================================================================
# FILE: views/exam_sheet.py
==========================================================================================
# PATH: apps/domains/exams/models/exam_sheet.py
from django.db import models


class ExamSheet(models.Model):
    """
    시험(exam)에서 사용하는 시험지(sheet)
    - 시험 실행 시 단일 진실
    """

    exam_id = models.PositiveIntegerField(db_index=True)
    sheet_id = models.PositiveIntegerField(db_index=True)

    class Meta:
        db_table = "exams_exam_sheet"
        unique_together = ("exam_id", "sheet_id")


==========================================================================================
# FILE: views/internal_ai_job_view.py
==========================================================================================
# PATH: apps/domains/ai/views/internal_ai_job_view.py
from __future__ import annotations

from typing import Any, Dict, Optional

from django.conf import settings
from rest_framework import status
from rest_framework.permissions import AllowAny
from rest_framework.response import Response
from rest_framework.views import APIView

from apps.shared.contracts.ai_job import AIJob as AIJobContract
from apps.domains.ai.models import AIJobModel, AIResultModel
from apps.domains.ai.queueing.db_queue import DBJobQueue


def _get_worker_token_secret() -> str:
    v = getattr(settings, "INTERNAL_WORKER_TOKEN", None)
    return str(v or "")


def _require_worker_auth(request) -> Optional[Response]:
    expected = _get_worker_token_secret()
    if not expected:
        return Response(
            {"detail": "INTERNAL_WORKER_TOKEN not configured"},
            status=status.HTTP_503_SERVICE_UNAVAILABLE,
        )

    token = request.headers.get("X-Worker-Token") or request.META.get("HTTP_X_WORKER_TOKEN") or ""
    if str(token) != str(expected):
        return Response({"detail": "Unauthorized worker"}, status=status.HTTP_401_UNAUTHORIZED)
    return None


def _worker_id(request) -> str:
    return request.headers.get("X-Worker-Id") or request.META.get("HTTP_X_WORKER_ID") or "ai-worker"


class InternalAIJobNextView(APIView):
    """
    GET /api/v1/internal/ai/job/next/
    response: { "job": {...} | null }
    """

    permission_classes = [AllowAny]

    def get(self, request):
        auth = _require_worker_auth(request)
        if auth:
            return auth

        q = DBJobQueue()
        claimed = q.claim(worker_id=_worker_id(request))
        if not claimed:
            return Response({"job": None}, status=status.HTTP_200_OK)

        job = AIJobContract.from_dict(
            {
                "id": claimed.job_id,
                "type": claimed.job_type,
                "payload": claimed.payload,
                "tenant_id": claimed.tenant_id,
                "source_domain": claimed.source_domain,
                "source_id": claimed.source_id,
            }
        )
        return Response({"job": job.to_dict()}, status=status.HTTP_200_OK)


class InternalAIJobResultView(APIView):
    """
    POST /api/v1/internal/ai/job/result/
    payload:
      {
        "job_id": "...",
        "submission_id": 123,      # optional legacy
        "status": "DONE|FAILED",
        "result": {...} | null,
        "error": "..." | null
      }
    """

    permission_classes = [AllowAny]

    def post(self, request):
        auth = _require_worker_auth(request)
        if auth:
            return auth

        data: Dict[str, Any] = request.data if isinstance(request.data, dict) else {}

        job_id = data.get("job_id")
        if not job_id:
            return Response({"detail": "job_id required"}, status=status.HTTP_400_BAD_REQUEST)

        status_in = str(data.get("status") or "DONE").upper().strip()
        if status_in not in ("DONE", "FAILED"):
            return Response({"detail": "status must be DONE or FAILED"}, status=status.HTTP_400_BAD_REQUEST)

        result = data.get("result")
        if result is not None and not isinstance(result, dict):
            return Response({"detail": "result must be object or null"}, status=status.HTTP_400_BAD_REQUEST)

        error = str(data.get("error") or "")

        job = AIJobModel.objects.filter(job_id=str(job_id)).first()
        if not job:
            return Response({"detail": "job not found"}, status=status.HTTP_404_NOT_FOUND)

        # idempotent: if result already stored, ignore duplicates
        if AIResultModel.objects.filter(job=job).exists():
            return Response({"ok": True, "detail": "duplicate_ignored"}, status=status.HTTP_200_OK)

        # store fact
        AIResultModel.objects.create(job=job, payload=(result or None))

        q = DBJobQueue()
        if status_in == "FAILED":
            q.mark_failed(job_id=job.job_id, error=error or "failed", retryable=True)
            return Response({"ok": True, "detail": "failed_recorded"}, status=status.HTTP_200_OK)

        q.mark_done(job_id=job.job_id)
        return Response({"ok": True, "detail": "done"}, status=status.HTTP_200_OK)
