====================================================================================================
# BACKEND APP: domains__ai
# ROOT PATH: C:\academy\apps\domains\ai
====================================================================================================


==========================================================================================
# FILE: __init__.py
==========================================================================================
# apps/domains/ai/__init__.py


==========================================================================================
# FILE: apps.py
==========================================================================================
# apps/domains/ai/apps.py
from django.apps import AppConfig


class AIDomainConfig(AppConfig):
    default_auto_field = "django.db.models.BigAutoField"
    name = "apps.domains.ai"
    label = "ai_domain"


==========================================================================================
# FILE: callbacks.py
==========================================================================================
# apps/domains/ai/callbacks.py
from apps.shared.contracts.ai_result import AIResult
from apps.domains.ai.models import AIJobModel
from apps.domains.submissions.services.ai_omr_result_mapper import apply_ai_result
from apps.domains.results.tasks.grading_tasks import grade_submission_task


def handle_ai_result(result: AIResult) -> None:
    """
    Worker → API callback entry

    규칙(무퇴화/정규화):
    - 상태(status) 변경은 Queue/API(SQS Queue)가 SSOT로 처리한다.
    - callbacks는 "도메인 후속 처리"만 담당한다.
    - 결과 fact(AIResultModel)는 API 계층에서 이미 저장되므로 여기서 생성/수정하지 않는다.
    """
    # callbacks가 job 존재를 전제로 동작 (gateway에서 job row를 선생성)
    AIJobModel.objects.get(job_id=result.job_id)

    if result.status == "FAILED":
        # 실패 상태/에러/재시도는 SQS Queue에서 처리됨
        return

    # DONE: submissions 로 위임 (답안 중간산물 저장)
    payload = result.result if isinstance(result.result, dict) else {}
    submission_id = apply_ai_result(payload)

    # 채점 실행 (Celery 제거됨, 동기 실행)
    if submission_id:
        grade_submission_task(int(submission_id))


==========================================================================================
# FILE: gateway.py
==========================================================================================
from __future__ import annotations

from typing import Any, Dict, Optional

import logging

from apps.shared.contracts.ai_job import AIJob
from apps.domains.ai.types import ensure_payload_dict, AIJobType
from apps.domains.ai.safe import safe_dispatch
from apps.domains.ai.queueing.publisher import publish_job
from apps.domains.ai.models import AIJobModel
from apps.domains.ai.services.tier_resolver import resolve_tier, validate_tier_for_job_type

logger = logging.getLogger(__name__)


def dispatch_job(
    *,
    job_type: AIJobType,
    payload: Dict[str, Any],
    tenant_id: Optional[str] = None,
    source_domain: Optional[str] = None,
    source_id: Optional[str] = None,
    tier: Optional[str] = None,  # "lite" | "basic" | "premium"
) -> Dict[str, Any]:
    """
    AI 작업 발행
    
    Args:
        job_type: 작업 타입
        payload: 작업 페이로드
        tenant_id: Tenant ID
        source_domain: 소스 도메인
        source_id: 소스 ID
        tier: Tier ("lite" | "basic" | "premium"), 기본값: "basic"
    """
    payload = ensure_payload_dict(payload)
    
    # Tier 결정 (명시적 tier 또는 자동 결정)
    if not tier:
        tier = resolve_tier(
            tenant_id=tenant_id,
            job_type=job_type,
            payload=payload,
        )
    tier = tier.lower()
    if tier not in ("lite", "basic", "premium"):
        tier = "basic"
    
    # Tier와 작업 타입 호환성 검증
    if not validate_tier_for_job_type(tier, job_type):
        logger.warning(
            "Tier %s is not compatible with job_type %s, using basic",
            tier,
            job_type,
        )
        tier = "basic"

    job = AIJob.new(
        type=job_type,
        payload=payload,
        tenant_id=tenant_id,
        source_domain=source_domain,
        source_id=source_id,
    )

    def _do():
        # ✅ callbacks가 AIJobModel을 조회하므로, 발행 시점에 반드시 저장
        job_model = AIJobModel.objects.create(
            job_id=job.id,
            job_type=job.type,
            payload=job.payload,
            status="PENDING",
            tier=tier,
            tenant_id=tenant_id,
            source_domain=source_domain,
            source_id=source_id,
        )

        try:
            publish_job(job)
        except Exception as e:
            job_model.status = "FAILED"
            job_model.error_message = str(e)
            job_model.last_error = str(e)
            job_model.save(update_fields=["status", "error_message", "last_error", "updated_at"])
            raise

        return {"ok": True, "job_id": job.id, "type": job.type}

    return safe_dispatch(_do, fallback={"ok": False, "job_id": job.id, "type": job.type})


==========================================================================================
# FILE: models.py
==========================================================================================
# apps/domains/ai/models.py
from __future__ import annotations

from django.db import models
from django.utils import timezone

from apps.core.models.base import BaseModel


class AIJobModel(BaseModel):
    """
    AI Job Meta (DB is SSOT)
    - API server owns lifecycle
    - Worker pulls via internal endpoints
    """

    job_id = models.CharField(max_length=64, unique=True)
    job_type = models.CharField(max_length=50)

    status = models.CharField(
        max_length=20,
        choices=[
            ("PENDING", "PENDING"),
            ("RUNNING", "RUNNING"),
            ("DONE", "DONE"),
            ("FAILED", "FAILED"),
        ],
        default="PENDING",
    )

    payload = models.JSONField(default=dict, blank=True)
    error_message = models.TextField(blank=True, default="")

    # ---- routing / trace ----
    tenant_id = models.CharField(max_length=64, null=True, blank=True)
    source_domain = models.CharField(max_length=64, null=True, blank=True)
    source_id = models.CharField(max_length=64, null=True, blank=True)
    
    # ---- tier routing ----
    tier = models.CharField(
        max_length=20,
        choices=[
            ("lite", "Lite"),
            ("basic", "Basic"),
            ("premium", "Premium"),
        ],
        default="basic",
        db_index=True,
        help_text="Tier determines queue routing and processing capabilities",
    )

    # ---- retry / lease ----
    attempt_count = models.IntegerField(default=0)
    max_attempts = models.IntegerField(default=5)

    locked_by = models.CharField(max_length=128, null=True, blank=True)
    locked_at = models.DateTimeField(null=True, blank=True)
    lease_expires_at = models.DateTimeField(null=True, blank=True)
    last_heartbeat_at = models.DateTimeField(null=True, blank=True)

    next_run_at = models.DateTimeField(default=timezone.now)
    last_error = models.TextField(blank=True, default="")

    class Meta:
        db_table = "ai_job"
        indexes = [
            models.Index(fields=["status", "next_run_at"], name="ai_job_status_next_run_idx"),
            models.Index(fields=["lease_expires_at"], name="ai_job_lease_idx"),
            models.Index(fields=["source_domain", "source_id"], name="ai_job_source_idx"),
            models.Index(fields=["tier", "status", "next_run_at"], name="ai_job_tier_stat_next_idx"),
        ]

    def __str__(self) -> str:
        return f"AIJobModel<{self.job_id}>({self.job_type})[{self.tier}][{self.status}]"


class AIResultModel(BaseModel):
    """
    AI Result Fact (write-once, idempotency anchor)
    - OneToOne to enforce single fact row per job
    """

    job = models.OneToOneField(
        AIJobModel,
        on_delete=models.CASCADE,
        related_name="result",
    )
    payload = models.JSONField(null=True, blank=True)

    class Meta:
        db_table = "ai_result"

    def __str__(self) -> str:
        return f"AIResultModel(job_id={self.job_id})"


==========================================================================================
# FILE: safe.py
==========================================================================================
# apps/domains/ai/safe.py
from __future__ import annotations

import logging
from typing import Any, Dict, Optional

logger = logging.getLogger(__name__)


def safe_dispatch(fn, *, fallback: Optional[Dict[str, Any]] = None, **kwargs) -> Dict[str, Any]:
    """
    AI Job 발행을 안전하게 감싼다.
    API는 실패해도 깨지면 안 된다.
    """
    try:
        return fn(**kwargs)
    except Exception as e:
        logger.exception("AI job dispatch failed", exc_info=e)
        return fallback or {"ok": False, "error": str(e)}


==========================================================================================
# FILE: types.py
==========================================================================================
from __future__ import annotations

from typing import Any, Dict, Literal, Optional, TypedDict


AIJobType = Literal[
    "ocr",
    "question_segmentation",
    "handwriting_analysis",
    "embedding",
    "problem_generation",
    "homework_video_analysis",
]


class OCRPayload(TypedDict, total=False):
    image_path: str
    engine: Optional[Literal["google", "tesseract", "auto"]]
    academy_id: Optional[int]


class SegmentationPayload(TypedDict, total=False):
    image_path: str
    engine: Optional[Literal["yolo", "opencv", "template", "auto"]]


class HandwritingPayload(TypedDict, total=False):
    image_path: str


class EmbeddingPayload(TypedDict, total=False):
    texts: list[str]
    backend: Optional[Literal["local", "openai", "auto"]]


class ProblemGenerationPayload(TypedDict, total=False):
    ocr_text: str
    model: Optional[str]


class HomeworkVideoPayload(TypedDict, total=False):
    video_path: str
    frame_stride: Optional[int]
    min_frame_count: Optional[int]


def ensure_payload_dict(payload: Any) -> Dict[str, Any]:
    if payload is None:
        return {}
    if isinstance(payload, dict):
        return payload
    raise TypeError("payload must be a dict")


==========================================================================================
# FILE: urls.py
==========================================================================================
# PATH: apps/domains/ai/urls.py
from django.urls import path

# ==================================================
# ✅ HTTP Polling 엔드포인트 제거됨 (SQS 기반 아키텍처로 전환)
#
# 제거된 엔드포인트:
# - /job/next/ (InternalAIJobNextView)
# - /job/result/ (InternalAIJobResultView)
#
# 새로운 아키텍처:
# - SQS 기반 큐 사용
# - Worker는 SQS Long Polling으로 작업 수신
# - 완료/실패는 AISQSQueue.complete_job() / fail_job() 사용
# ==================================================

urlpatterns = [
    # HTTP polling 엔드포인트는 모두 제거됨
    # SQS 기반 아키텍처로 전환 완료
]


==========================================================================================
# FILE: migrations/0001_initial.py
==========================================================================================
# Generated by Django 5.2.9 on 2026-01-06 02:52

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = []

    operations = [
        migrations.CreateModel(
            name="AIJobModel",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("updated_at", models.DateTimeField(auto_now=True)),
                ("job_id", models.CharField(max_length=64, unique=True)),
                ("job_type", models.CharField(max_length=50)),
                (
                    "status",
                    models.CharField(
                        choices=[
                            ("PENDING", "PENDING"),
                            ("RUNNING", "RUNNING"),
                            ("DONE", "DONE"),
                            ("FAILED", "FAILED"),
                        ],
                        default="PENDING",
                        max_length=20,
                    ),
                ),
                ("payload", models.JSONField()),
                ("error_message", models.TextField(blank=True)),
            ],
            options={
                "db_table": "ai_job",
            },
        ),
        migrations.CreateModel(
            name="AIResultModel",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("updated_at", models.DateTimeField(auto_now=True)),
                ("payload", models.JSONField(blank=True, null=True)),
                (
                    "job",
                    models.OneToOneField(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="result",
                        to="ai_domain.aijobmodel",
                    ),
                ),
            ],
            options={
                "db_table": "ai_result",
            },
        ),
    ]


==========================================================================================
# FILE: migrations/0002_job_queue_fields.py
==========================================================================================
# Generated by Django 5.2.x on 2026-01-31
from django.db import migrations, models
import django.utils.timezone


class Migration(migrations.Migration):

    dependencies = [
        ("ai_domain", "0001_initial"),
    ]

    operations = [
        migrations.AddField(
            model_name="aijobmodel",
            name="tenant_id",
            field=models.CharField(blank=True, max_length=64, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="source_domain",
            field=models.CharField(blank=True, max_length=64, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="source_id",
            field=models.CharField(blank=True, max_length=64, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="attempt_count",
            field=models.IntegerField(default=0),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="max_attempts",
            field=models.IntegerField(default=5),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="locked_by",
            field=models.CharField(blank=True, max_length=128, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="locked_at",
            field=models.DateTimeField(blank=True, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="lease_expires_at",
            field=models.DateTimeField(blank=True, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="last_heartbeat_at",
            field=models.DateTimeField(blank=True, null=True),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="next_run_at",
            field=models.DateTimeField(default=django.utils.timezone.now),
        ),
        migrations.AddField(
            model_name="aijobmodel",
            name="last_error",
            field=models.TextField(blank=True, default=""),
        ),
        migrations.AddIndex(
            model_name="aijobmodel",
            index=models.Index(fields=["status", "next_run_at"], name="ai_job_status_next_run_idx"),
        ),
        migrations.AddIndex(
            model_name="aijobmodel",
            index=models.Index(fields=["lease_expires_at"], name="ai_job_lease_idx"),
        ),
        migrations.AddIndex(
            model_name="aijobmodel",
            index=models.Index(fields=["source_domain", "source_id"], name="ai_job_source_idx"),
        ),
    ]


==========================================================================================
# FILE: migrations/0003_alter_aijobmodel_status_and_more.py
==========================================================================================
# Generated by Django 5.2.9 on 2026-01-31 02:51

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("ai_domain", "0002_job_queue_fields"),
    ]

    operations = [
        migrations.AlterField(
            model_name="aijobmodel",
            name="status",
            field=models.CharField(
                choices=[
                    ("PENDING", "PENDING"),
                    ("RUNNING", "RUNNING"),
                    ("DONE", "DONE"),
                    ("FAILED", "FAILED"),
                ],
                db_index=True,
                default="PENDING",
                max_length=20,
            ),
        ),
        migrations.AddIndex(
            model_name="aijobmodel",
            index=models.Index(
                fields=["status", "created_at"], name="ai_job_status_ba4967_idx"
            ),
        ),
        migrations.AddIndex(
            model_name="aijobmodel",
            index=models.Index(fields=["locked_at"], name="ai_job_locked__f6f4a2_idx"),
        ),
    ]


==========================================================================================
# FILE: migrations/0004_remove_aijobmodel_ai_job_status_ba4967_idx_and_more.py
==========================================================================================
# Generated by Django 5.2.9 on 2026-01-31 03:56

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("ai_domain", "0003_alter_aijobmodel_status_and_more"),
    ]

    operations = [
        migrations.RemoveIndex(
            model_name="aijobmodel",
            name="ai_job_status_ba4967_idx",
        ),
        migrations.RemoveIndex(
            model_name="aijobmodel",
            name="ai_job_locked__f6f4a2_idx",
        ),
        migrations.AlterField(
            model_name="aijobmodel",
            name="status",
            field=models.CharField(
                choices=[
                    ("PENDING", "PENDING"),
                    ("RUNNING", "RUNNING"),
                    ("DONE", "DONE"),
                    ("FAILED", "FAILED"),
                ],
                default="PENDING",
                max_length=20,
            ),
        ),
    ]


==========================================================================================
# FILE: migrations/0005_alter_aijobmodel_error_message_and_more.py
==========================================================================================
# Generated by Django 5.2.9 on 2026-01-31 14:51

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("ai_domain", "0004_remove_aijobmodel_ai_job_status_ba4967_idx_and_more"),
    ]

    operations = [
        migrations.AlterField(
            model_name="aijobmodel",
            name="error_message",
            field=models.TextField(blank=True, default=""),
        ),
        migrations.AlterField(
            model_name="aijobmodel",
            name="payload",
            field=models.JSONField(blank=True, default=dict),
        ),
    ]


==========================================================================================
# FILE: migrations/0006_add_tier_field.py
==========================================================================================
# Generated migration: Add tier field to AIJobModel

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('ai_domain', '0005_alter_aijobmodel_error_message_and_more'),
    ]

    operations = [
        migrations.AddField(
            model_name='aijobmodel',
            name='tier',
            field=models.CharField(
                max_length=20,
                choices=[
                    ('lite', 'Lite'),
                    ('basic', 'Basic'),
                    ('premium', 'Premium'),
                ],
                default='basic',
                db_index=True,
                help_text='Tier determines queue routing and processing capabilities',
            ),
        ),
        migrations.AddIndex(
            model_name='aijobmodel',
            index=models.Index(fields=['tier', 'status', 'next_run_at'], name='ai_job_tier_stat_next_idx'),
        ),
    ]


==========================================================================================
# FILE: migrations/__init__.py
==========================================================================================



==========================================================================================
# FILE: queueing/__init__.py
==========================================================================================
# apps/domains/ai/queueing/__init__.py


==========================================================================================
# FILE: queueing/db_queue.py
==========================================================================================
# apps/domains/ai/queueing/db_queue.py
from __future__ import annotations

from dataclasses import dataclass
from datetime import timedelta
from typing import Optional

from django.db import transaction
from django.utils import timezone

from apps.domains.ai.models import AIJobModel
from apps.domains.ai.queueing.interfaces import JobQueue, ClaimedJob


@dataclass(frozen=True)
class DBQueueConfig:
    visibility_timeout_sec: int = 120  # lease duration
    default_max_attempts: int = 5
    base_backoff_sec: int = 2
    max_backoff_sec: int = 120


class DBJobQueue(JobQueue):
    """
    SQS-style lease/visibility timeout on DB.
    - DB is SSOT
    - Worker is stateless
    - Crash recovery via lease expiry
    """

    def __init__(self, cfg: Optional[DBQueueConfig] = None):
        self.cfg = cfg or DBQueueConfig()

    def publish(self, *, job_id: str) -> None:
        now = timezone.now()
        AIJobModel.objects.filter(job_id=job_id).update(
            status="PENDING",
            next_run_at=now,
        )

    @transaction.atomic
    def claim(self, *, worker_id: str) -> Optional[ClaimedJob]:
        now = timezone.now()

        # 0) reclaim stale RUNNING jobs
        AIJobModel.objects.select_for_update().filter(
            status="RUNNING",
            lease_expires_at__isnull=False,
            lease_expires_at__lt=now,
        ).update(
            status="PENDING",
            locked_by=None,
            locked_at=None,
            lease_expires_at=None,
        )

        # 1) pick next runnable
        qs = (
            AIJobModel.objects.select_for_update(skip_locked=True)
            .filter(status="PENDING", next_run_at__lte=now)
            .order_by("next_run_at", "created_at")
        )

        job = qs.first()
        if not job:
            return None

        # 2) attempts + lease
        attempt = int(job.attempt_count or 0) + 1
        max_attempts = int(job.max_attempts or self.cfg.default_max_attempts)
        if attempt > max_attempts:
            job.status = "FAILED"
            job.error_message = job.error_message or "max_attempts_exceeded"
            job.last_error = job.last_error or "max_attempts_exceeded"
            job.save(update_fields=["status", "error_message", "last_error", "updated_at"])
            return None

        lease_expires = now + timedelta(seconds=self.cfg.visibility_timeout_sec)
        job.status = "RUNNING"
        job.attempt_count = attempt
        job.max_attempts = max_attempts
        job.locked_by = str(worker_id)
        job.locked_at = now
        job.lease_expires_at = lease_expires
        job.last_heartbeat_at = now
        job.save(
            update_fields=[
                "status",
                "attempt_count",
                "max_attempts",
                "locked_by",
                "locked_at",
                "lease_expires_at",
                "last_heartbeat_at",
                "updated_at",
            ]
        )

        return ClaimedJob(
            job_id=job.job_id,
            job_type=job.job_type,
            payload=job.payload or {},
            tenant_id=job.tenant_id,
            source_domain=job.source_domain,
            source_id=job.source_id,
            locked_by=job.locked_by,
        )

    def heartbeat(self, *, job_id: str, worker_id: str) -> None:
        now = timezone.now()
        AIJobModel.objects.filter(job_id=job_id, locked_by=str(worker_id), status="RUNNING").update(
            last_heartbeat_at=now,
            updated_at=now,
        )

    def mark_done(self, *, job_id: str) -> None:
        AIJobModel.objects.filter(job_id=job_id).update(
            status="DONE",
            error_message="",
            updated_at=timezone.now(),
        )

    def mark_failed(self, *, job_id: str, error: str, retryable: bool = True) -> None:
        """
        실패 처리 + retry/backoff
        - retryable=True & attempt_count < max_attempts => PENDING with next_run_at(backoff)
        - else => FAILED
        """
        now = timezone.now()
        job = AIJobModel.objects.filter(job_id=job_id).first()
        if not job:
            return

        attempt = int(job.attempt_count or 0)
        max_attempts = int(job.max_attempts or self.cfg.default_max_attempts)

        backoff = min(self.cfg.max_backoff_sec, (2 ** max(0, attempt - 1)) * self.cfg.base_backoff_sec)
        next_run = now + timedelta(seconds=int(backoff))

        err = str(error or "")[:5000]

        if retryable and attempt < max_attempts:
            AIJobModel.objects.filter(job_id=job_id).update(
                status="PENDING",
                last_error=err,
                error_message=err,
                next_run_at=next_run,
                locked_by=None,
                locked_at=None,
                lease_expires_at=None,
                updated_at=now,
            )
            return

        AIJobModel.objects.filter(job_id=job_id).update(
            status="FAILED",
            last_error=err,
            error_message=err,
            locked_by=None,
            locked_at=None,
            lease_expires_at=None,
            updated_at=now,
        )


==========================================================================================
# FILE: queueing/interfaces.py
==========================================================================================
# apps/domains/ai/queueing/interfaces.py
from __future__ import annotations

from dataclasses import dataclass
from typing import Optional, Protocol, Dict, Any


@dataclass(frozen=True)
class ClaimedJob:
    job_id: str
    job_type: str
    payload: Dict[str, Any]
    tenant_id: Optional[str] = None
    source_domain: Optional[str] = None
    source_id: Optional[str] = None

    # lease/debug
    locked_by: Optional[str] = None


class JobQueue(Protocol):
    def publish(self, *, job_id: str) -> None:
        ...

    def claim(self, *, worker_id: str) -> Optional[ClaimedJob]:
        ...

    def heartbeat(self, *, job_id: str, worker_id: str) -> None:
        ...

    def mark_done(self, *, job_id: str) -> None:
        ...

    def mark_failed(self, *, job_id: str, error: str, retryable: bool = True) -> None:
        ...


==========================================================================================
# FILE: queueing/publisher.py
==========================================================================================
# apps/domains/ai/queueing/publisher.py
from __future__ import annotations

import logging
from apps.shared.contracts.ai_job import AIJob
from apps.domains.ai.models import AIJobModel

logger = logging.getLogger(__name__)


def publish_ai_job_sqs(job_model: AIJobModel) -> None:
    """
    SQS 큐에 AI 작업 발행 (Tier별 라우팅)
    
    Args:
        job_model: AIJobModel 객체 (tier 필드 포함)
    """
    from apps.support.ai.services.sqs_queue import AISQSQueue
    
    queue = AISQSQueue()
    queue.enqueue(job_model)


# ----------------------------------------------------------------------
# Backward-compat export (SSOT)
# gateway.py 등에서 publish_job 이름을 기대하는 경우가 많아 alias로 봉인한다.
# ----------------------------------------------------------------------
def publish_job(job: AIJob) -> None:
    """
    Public publisher entrypoint (SSOT).
    
    SQS 큐만 사용 (Redis 제거됨)
    Tier는 AIJobModel에서 가져옴
    """
    from apps.domains.ai.models import AIJobModel
    
    # AIJobModel에서 tier 가져오기
    job_model = AIJobModel.objects.filter(job_id=str(job.id)).first()
    if job_model:
        publish_ai_job_sqs(job_model)
    else:
        logger.warning("AIJobModel not found for job %s, using basic tier", job.id)
        # 기본값으로 basic tier 사용
        job_model = AIJobModel.objects.create(
            job_id=job.id,
            job_type=job.type,
            payload=job.payload or {},
            status="PENDING",
            tier="basic",
        )
        publish_ai_job_sqs(job_model)


==========================================================================================
# FILE: services/tier_resolver.py
==========================================================================================
"""
Tier 결정 로직

비즈니스 규칙:
- Lite: CPU OCR만 허용 (복지 티어)
- Basic: CPU 기반 OMR/status detection + 개선된 CPU OCR
- Premium: GPU 기반 전체 OCR + 고급 분석 (향후)
"""

from __future__ import annotations

import logging
from typing import Optional

from django.conf import settings

logger = logging.getLogger(__name__)


def resolve_tier(
    *,
    tenant_id: Optional[str] = None,
    job_type: str,
    payload: dict,
) -> str:
    """
    작업의 Tier 결정
    
    Args:
        tenant_id: Tenant ID (선택사항, tenant별 tier 설정 가능)
        job_type: 작업 타입 (예: "ocr", "omr_grading")
        payload: 작업 페이로드
        
    Returns:
        str: "lite" | "basic" | "premium"
    """
    # 1. 명시적 tier 지정 (payload에서)
    explicit_tier = payload.get("tier")
    if explicit_tier in ("lite", "basic", "premium"):
        return explicit_tier.lower()
    
    # 2. Tenant별 tier 설정 (향후 확장 가능)
    # tenant_tier = get_tenant_tier(tenant_id) if tenant_id else None
    # if tenant_tier:
    #     return tenant_tier
    
    # 3. 작업 타입 기반 기본 tier 결정
    job_type_lower = job_type.lower()
    
    # OCR만 필요한 작업 -> Lite 가능
    if job_type_lower in ("ocr",):
        # 기본값: basic (향후 tenant 설정으로 lite 가능)
        return "basic"
    
    # OMR/status detection -> Basic 이상 필요
    if job_type_lower in ("omr_grading", "homework_video_analysis"):
        return "basic"
    
    # 고급 분석 -> Premium 필요 (향후)
    if job_type_lower in ("advanced_analysis", "full_ocr"):
        return "premium"
    
    # 기본값: basic
    return "basic"


def validate_tier_for_job_type(tier: str, job_type: str) -> bool:
    """
    Tier와 작업 타입의 호환성 검증
    
    Args:
        tier: Tier ("lite" | "basic" | "premium")
        job_type: 작업 타입
        
    Returns:
        bool: 호환 가능 여부
    """
    tier = tier.lower()
    job_type_lower = job_type.lower()
    
    # Lite: OCR만 허용
    if tier == "lite":
        return job_type_lower in ("ocr",)
    
    # Basic: OCR + OMR/status detection
    if tier == "basic":
        return job_type_lower in ("ocr", "omr_grading", "homework_video_analysis")
    
    # Premium: 모든 작업 허용
    if tier == "premium":
        return True
    
    return False


==========================================================================================
# FILE: services/worker_instance_control.py
==========================================================================================
# PATH: apps/domains/ai/services/worker_instance_control.py

import boto3
import logging

logger = logging.getLogger(__name__)

REGION = "ap-northeast-2"
AI_WORKER_INSTANCE_ID = "i-0f52f9d89481385a8"  # 네 실제 워커 EC2

def start_ai_worker_instance():
    """
    API 서버에서 호출
    - AI 워커 EC2를 켜기만 함
    - stop은 절대 여기서 하지 않음
    """
    ec2 = boto3.client("ec2", region_name=REGION)

    logger.info("[AI] Starting AI worker EC2 instance")

    ec2.start_instances(
        InstanceIds=[AI_WORKER_INSTANCE_ID]
    )


==========================================================================================
# FILE: views/__init__.py
==========================================================================================
# PATH: apps/domains/ai/views/__init__.py
# empty


==========================================================================================
# FILE: views/exam_sheet.py
==========================================================================================
# PATH: apps/domains/exams/models/exam_sheet.py
from django.db import models


class ExamSheet(models.Model):
    """
    시험(exam)에서 사용하는 시험지(sheet)
    - 시험 실행 시 단일 진실
    """

    exam_id = models.PositiveIntegerField(db_index=True)
    sheet_id = models.PositiveIntegerField(db_index=True)

    class Meta:
        db_table = "exams_exam_sheet"
        unique_together = ("exam_id", "sheet_id")


==========================================================================================
# FILE: views/internal_ai_job_view.py
==========================================================================================
# PATH: apps/domains/ai/views/internal_ai_job_view.py
from __future__ import annotations

from typing import Any, Dict, Optional

from django.conf import settings
from rest_framework import status
from rest_framework.permissions import AllowAny
from rest_framework.response import Response
from rest_framework.views import APIView

from apps.shared.contracts.ai_job import AIJob as AIJobContract
from apps.domains.ai.models import AIJobModel, AIResultModel
from apps.domains.ai.queueing.db_queue import DBJobQueue


def _get_worker_token_secret() -> str:
    v = getattr(settings, "INTERNAL_WORKER_TOKEN", None)
    return str(v or "")


def _require_worker_auth(request) -> Optional[Response]:
    expected = _get_worker_token_secret()
    if not expected:
        return Response(
            {"detail": "INTERNAL_WORKER_TOKEN not configured"},
            status=status.HTTP_503_SERVICE_UNAVAILABLE,
        )

    token = request.headers.get("X-Worker-Token") or request.META.get("HTTP_X_WORKER_TOKEN") or ""
    if str(token) != str(expected):
        return Response({"detail": "Unauthorized worker"}, status=status.HTTP_401_UNAUTHORIZED)
    return None


def _worker_id(request) -> str:
    return request.headers.get("X-Worker-Id") or request.META.get("HTTP_X_WORKER_ID") or "ai-worker"


class InternalAIJobNextView(APIView):
    """
    GET /api/v1/internal/ai/job/next/
    response: { "job": {...} | null }
    """

    permission_classes = [AllowAny]

    def get(self, request):
        auth = _require_worker_auth(request)
        if auth:
            return auth

        q = DBJobQueue()
        claimed = q.claim(worker_id=_worker_id(request))
        if not claimed:
            return Response({"job": None}, status=status.HTTP_200_OK)

        job = AIJobContract.from_dict(
            {
                "id": claimed.job_id,
                "type": claimed.job_type,
                "payload": claimed.payload,
                "tenant_id": claimed.tenant_id,
                "source_domain": claimed.source_domain,
                "source_id": claimed.source_id,
            }
        )
        return Response({"job": job.to_dict()}, status=status.HTTP_200_OK)


class InternalAIJobResultView(APIView):
    """
    POST /api/v1/internal/ai/job/result/
    payload:
      {
        "job_id": "...",
        "submission_id": 123,      # optional legacy
        "status": "DONE|FAILED",
        "result": {...} | null,
        "error": "..." | null
      }
    """

    permission_classes = [AllowAny]

    def post(self, request):
        auth = _require_worker_auth(request)
        if auth:
            return auth

        data: Dict[str, Any] = request.data if isinstance(request.data, dict) else {}

        job_id = data.get("job_id")
        if not job_id:
            return Response({"detail": "job_id required"}, status=status.HTTP_400_BAD_REQUEST)

        status_in = str(data.get("status") or "DONE").upper().strip()
        if status_in not in ("DONE", "FAILED"):
            return Response({"detail": "status must be DONE or FAILED"}, status=status.HTTP_400_BAD_REQUEST)

        result = data.get("result")
        if result is not None and not isinstance(result, dict):
            return Response({"detail": "result must be object or null"}, status=status.HTTP_400_BAD_REQUEST)

        error = str(data.get("error") or "")

        job = AIJobModel.objects.filter(job_id=str(job_id)).first()
        if not job:
            return Response({"detail": "job not found"}, status=status.HTTP_404_NOT_FOUND)

        # idempotent: if result already stored, ignore duplicates
        if AIResultModel.objects.filter(job=job).exists():
            return Response({"ok": True, "detail": "duplicate_ignored"}, status=status.HTTP_200_OK)

        # store fact
        AIResultModel.objects.create(job=job, payload=(result or None))

        q = DBJobQueue()
        if status_in == "FAILED":
            q.mark_failed(job_id=job.job_id, error=error or "failed", retryable=True)
            return Response({"ok": True, "detail": "failed_recorded"}, status=status.HTTP_200_OK)

        q.mark_done(job_id=job.job_id)
        return Response({"ok": True, "detail": "done"}, status=status.HTTP_200_OK)
