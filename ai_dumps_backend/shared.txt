====================================================================================================
# BACKEND APP: shared
# ROOT PATH: C:\academy\apps\shared
====================================================================================================


==========================================================================================
# FILE: __init__.py
==========================================================================================
# apps/shared/__init__.py
default_app_config = "apps.shared.apps.SharedConfig"


==========================================================================================
# FILE: apps.py
==========================================================================================
# apps/shared/apps.py
from django.apps import AppConfig

class SharedConfig(AppConfig):
    name = "apps.shared"


==========================================================================================
# FILE: contracts/__init__.py
==========================================================================================



==========================================================================================
# FILE: contracts/ai_job.py
==========================================================================================
# apps/shared/contracts/ai_job.py
from __future__ import annotations

from dataclasses import dataclass, asdict
from typing import Any, Dict, Literal, Optional
import json
import uuid
from datetime import datetime, timezone


AIJobType = Literal[
    "ocr",
    "question_segmentation",
    "handwriting_analysis",
    "embedding",
    "problem_generation",
    "homework_video_analysis",
    "omr_grading",
]


def _now_iso() -> str:
    return datetime.now(timezone.utc).isoformat()


@dataclass(frozen=True)
class AIJob:
    """
    API â†’ Worker ë¡œ ì „ë‹¬ë˜ëŠ” 'ê³„ì•½' (Contract)

    ì›ì¹™:
    - WorkerëŠ” DB/ORM/ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ë§¥ì„ ëª°ë¼ì•¼ í•˜ë¯€ë¡œ
      job payloadì—ëŠ” file path / ids / ìµœì†Œ ë©”íƒ€ë§Œ ë‹´ëŠ”ë‹¤.
    """

    id: str
    type: AIJobType

    # í…Œë„ŒíŠ¸/ìŠ¤ì½”í•‘ (APIì—ì„œë§Œ ì˜ë¯¸ ìžˆìŒ. workerëŠ” ê·¸ëŒ€ë¡œ echoë§Œ)
    tenant_id: Optional[str] = None

    # ì–´ë–¤ ë„ë©”ì¸ ì´ë²¤íŠ¸ì—ì„œ ë°œìƒí–ˆëŠ”ì§€ ì¶”ì ìš©
    source_domain: Optional[str] = None  # e.g. "submissions", "exams", "homework"
    source_id: Optional[str] = None      # e.g. submission_id

    # ì‹¤ì œ ì²˜ë¦¬ì— í•„ìš”í•œ ë°ì´í„°
    payload: Dict[str, Any] = None  # type: ignore

    # ì¶”ì 
    created_at: str = ""

    @staticmethod
    def new(
        *,
        type: AIJobType,
        payload: Dict[str, Any],
        tenant_id: Optional[str] = None,
        source_domain: Optional[str] = None,
        source_id: Optional[str] = None,
    ) -> "AIJob":
        return AIJob(
            id=str(uuid.uuid4()),
            type=type,
            tenant_id=tenant_id,
            source_domain=source_domain,
            source_id=source_id,
            payload=payload or {},
            created_at=_now_iso(),
        )

    def to_dict(self) -> Dict[str, Any]:
        d = asdict(self)
        if d["payload"] is None:
            d["payload"] = {}
        return d

    def to_json(self) -> str:
        return json.dumps(self.to_dict(), ensure_ascii=False)

    @staticmethod
    def from_dict(data: Dict[str, Any]) -> "AIJob":
        return AIJob(
            id=str(data.get("id")),
            type=data.get("type"),
            tenant_id=data.get("tenant_id"),
            source_domain=data.get("source_domain"),
            source_id=data.get("source_id"),
            payload=data.get("payload") or {},
            created_at=str(data.get("created_at") or ""),
        )

    @staticmethod
    def from_json(raw: str) -> "AIJob":
        return AIJob.from_dict(json.loads(raw))


==========================================================================================
# FILE: contracts/ai_result.py
==========================================================================================
# apps/shared/contracts/ai_result.py
from __future__ import annotations

from dataclasses import dataclass, asdict
from typing import Any, Dict, Literal, Optional
import json
from datetime import datetime, timezone


AIJobStatus = Literal["DONE", "FAILED"]


def _now_iso() -> str:
    return datetime.now(timezone.utc).isoformat()


@dataclass(frozen=True)
class AIResult:
    """
    Worker â†’ API ë¡œ ì „ë‹¬ë˜ëŠ” 'ê³„ì•½' (Contract)

    ì›ì¹™:
    - WorkerëŠ” ì €ìž¥í•˜ì§€ ì•ŠëŠ”ë‹¤. ê²°ê³¼ë¥¼ 'ì „ë‹¬'ë§Œ í•œë‹¤.
    - APIëŠ” ê²°ê³¼ë¥¼ ë°›ì•„ì„œ results/facts í˜¹ì€ submission meta ë“±ì— ë°˜ì˜í•œë‹¤.
    """

    job_id: str
    status: AIJobStatus

    # ê²°ê³¼ ë°ì´í„° (job type ë³„ ìŠ¤í‚¤ë§ˆëŠ” payload/resultë¡œ êµ¬ë¶„)
    result: Dict[str, Any] = None  # type: ignore

    # ì˜¤ë¥˜ ì •ë³´
    error: Optional[str] = None

    finished_at: str = ""

    @staticmethod
    def done(job_id: str, result: Dict[str, Any]) -> "AIResult":
        return AIResult(
            job_id=job_id,
            status="DONE",
            result=result or {},
            error=None,
            finished_at=_now_iso(),
        )

    @staticmethod
    def failed(job_id: str, error: str) -> "AIResult":
        return AIResult(
            job_id=job_id,
            status="FAILED",
            result={},
            error=error,
            finished_at=_now_iso(),
        )

    def to_dict(self) -> Dict[str, Any]:
        d = asdict(self)
        if d["result"] is None:
            d["result"] = {}
        return d

    def to_json(self) -> str:
        return json.dumps(self.to_dict(), ensure_ascii=False)

    @staticmethod
    def from_dict(data: Dict[str, Any]) -> "AIResult":
        return AIResult(
            job_id=str(data.get("job_id")),
            status=data.get("status"),
            result=data.get("result") or {},
            error=data.get("error"),
            finished_at=str(data.get("finished_at") or ""),
        )

    @staticmethod
    def from_json(raw: str) -> "AIResult":
        return AIResult.from_dict(json.loads(raw))


==========================================================================================
# FILE: contracts/message_job.py
==========================================================================================



==========================================================================================
# FILE: tasks/__init__.py
==========================================================================================
# apps/shared/tasks/__init__.py

from . import media


==========================================================================================
# FILE: tasks/ai.py
==========================================================================================
from celery import shared_task
from apps.shared.contracts.ai_job import AIJob
from apps.worker.ai.pipelines.dispatcher import handle_ai_job

@shared_task(
    bind=True,
    queue="ai",
    autoretry_for=(Exception,),
    retry_backoff=10,
    retry_kwargs={"max_retries": 3},
)
def run_ai_job(self, job_dict: dict):
    job = AIJob.from_dict(job_dict)
    result = handle_ai_job(job)
    return result.to_dict()


==========================================================================================
# FILE: tasks/media.py
==========================================================================================
from __future__ import annotations
# ì–˜ëŠ” ë§¨ìœ„ì— ìžˆì–´ì•¼í•¨. ë¬´ì¡°ê±´ !!! 

# apps/shared/tasks/media.py
print("ðŸ”¥ media task module imported ðŸ”¥")

import logging
from pathlib import Path

import requests
from celery import shared_task
from django.conf import settings
from django.db import transaction

from libs.s3_client.presign import create_presigned_get_url
from apps.worker.media.video.processor import run as run_processor
from apps.worker.media.video.processor import MediaProcessingError
from apps.worker.media.r2_uploader import upload_dir

logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------

def _get_hls_output_root(video_id: int) -> Path:
    """
    storage/media/hls/videos/{video_id}
    """
    return (
        Path(settings.BASE_DIR)
        / "storage"
        / "media"
        / "hls"
        / "videos"
        / str(video_id)
    )


def _to_relative_media_path(path: Path) -> str:
    """
    Convert absolute path under BASE_DIR/storage to relative media path.
    """
    base = Path(settings.BASE_DIR)
    try:
        return str(path.relative_to(base))
    except ValueError:
        return str(path)


def notify_processing_complete(
    *,
    video_id: int,
    hls_path: str,
    duration: int | None,
) -> None:
    """
    Worker -> API ACK
    """
    url = f"{settings.API_BASE_URL}/api/v1/internal/videos/{video_id}/processing-complete/"

    headers = {
        "X-Worker-Token": settings.INTERNAL_WORKER_TOKEN,
        "Content-Type": "application/json",
    }

    payload = {
        "hls_path": hls_path,
        "duration": duration,
    }

    resp = requests.post(url, json=payload, headers=headers, timeout=5)
    resp.raise_for_status()


# ---------------------------------------------------------------------
# Celery Task (ðŸ”¥ ì´ê²Œ í•µì‹¬)
# ---------------------------------------------------------------------

@shared_task(
    bind=True,
    queue="video",
    autoretry_for=(),
    retry_backoff=False,
)
def process_video_media(self, video_id: int) -> None:
    """
    Orchestrates media processing for a single Video.
    """

    # âš ï¸ ì¤‘ìš”: ì—¬ê¸°ì„œ import (Celery/Django ë¡œë”© ìˆœì„œ ë¬¸ì œ ë°©ì§€)
    from apps.support.media.models import Video

    logger.info("[media] Start processing (video_id=%s)", video_id)

    # 1ï¸âƒ£ Lock & ìƒíƒœ ì „ì´
    with transaction.atomic():
        video = (
            Video.objects
            .select_for_update()
            .filter(id=video_id)
            .first()
        )

        if video is None:
            logger.warning("[media] Video not found (video_id=%s)", video_id)
            return

        if video.status != Video.Status.UPLOADED:
            logger.info(
                "[media] Skip processing (status=%s, video_id=%s)",
                video.status,
                video_id,
            )
            return

        video.status = Video.Status.PROCESSING
        video.save(update_fields=["status"])

    # 2ï¸âƒ£ ìž…ë ¥ URL + ì¶œë ¥ ê²½ë¡œ ì¤€ë¹„
    try:
        input_url = create_presigned_get_url(
            key=video.file_key,
            expires_in=60 * 60,
        )
        output_root = _get_hls_output_root(video_id)

    except Exception:
        logger.exception(
            "[media] Failed to prepare input/output (video_id=%s)",
            video_id,
        )
        _mark_failed(video_id)
        return

    # 3ï¸âƒ£ ì‹¤ì œ ì²˜ë¦¬ (ffmpeg + HLS)
    try:
        result = run_processor(
            video_id=video_id,
            input_url=input_url,
            output_root=output_root,
        )

    except MediaProcessingError as e:
        logger.error(
            "[media] Media processing failed (video_id=%s) %s",
            video_id,
            e.to_dict(),
        )
        print("ðŸ”¥ MEDIA PROCESSING ERROR ðŸ”¥", e.to_dict())
        logger.error(
            "[media] Media processing failed (video_id=%s) %s",
            video_id,
            e.to_dict(),
        )

        _mark_failed(video_id)
        return

    except Exception:
        logger.exception(
            "[media] Unexpected error during media processing (video_id=%s)",
            video_id,
        )
        _mark_failed(video_id)
        return

    # 4ï¸âƒ£ DB ê²°ê³¼ ë°˜ì˜ (READY)
    with transaction.atomic():
        video = (
            Video.objects
            .select_for_update()
            .filter(id=video_id)
            .first()
        )

        if video is None:
            logger.warning(
                "[media] Video disappeared before READY persist (video_id=%s)",
                video_id,
            )
            return

        video.duration = result.duration_seconds
        video.thumbnail = _to_relative_media_path(result.thumbnail_path)
        video.hls_path = _to_relative_media_path(result.master_playlist_path)
        video.status = Video.Status.READY

        video.save(
            update_fields=[
                "duration",
                "thumbnail",
                "hls_path",
                "status",
            ]
        )

    # 5ï¸âƒ£ R2 ì—…ë¡œë“œ (ðŸš¨ íŠ¸ëžœìž­ì…˜ ë°–)
    try:
        upload_dir(
            local_dir=output_root,
            prefix=f"media/hls/videos/{video_id}",
        )
    except Exception:
        logger.exception(
            "[media] R2 upload failed (video_id=%s)",
            video_id,
        )
        _mark_failed(video_id)
        return

    logger.info(
        "[media] Video media processing READY (video_id=%s)",
        video_id,
    )

    # 6ï¸âƒ£ API í†µì§€ (ì‹¤íŒ¨í•´ë„ READYëŠ” ìœ ì§€)
    try:
        notify_processing_complete(
            video_id=video_id,
            hls_path=str(video.hls_path),
            duration=video.duration,
        )
        logger.info(
            "[media] Video processing notified API (video_id=%s)",
            video_id,
        )
    except Exception:
        logger.exception(
            "[media] Failed to notify API (video_id=%s)",
            video_id,
        )


# ---------------------------------------------------------------------
# Failure handling
# ---------------------------------------------------------------------

def _mark_failed(video_id: int) -> None:
    """
    Mark Video as FAILED.
    """
    from apps.support.media.models import Video

    with transaction.atomic():
        video = (
            Video.objects
            .select_for_update()
            .filter(id=video_id)
            .first()
        )
        if video is None:
            return

        video.status = Video.Status.FAILED
        video.save(update_fields=["status"])
