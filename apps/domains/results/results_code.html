
<!DOCTYPE html>
<html lang="ko">
<head>
<meta charset="utf-8">
<title>results Code Browser</title>
<style>
body {
    background:#0f1115;
    color:#eaeaea;
    font-family:Consolas, monospace;
    padding:24px;
}
h1 { margin-bottom:24px; }
h2 { color:#7dd3fc; font-size:15px; }
pre {
    background:#111418;
    padding:16px;
    border-radius:8px;
    overflow-x:auto;
    font-size:13px;
    line-height:1.5;
}
section { margin-bottom:32px; }
</style>
</head>
<body>
<h1>üì¶ apps\domains\results</h1>

        <section>
            <h2>__init__.py</h2>
            <pre><code></code></pre>
        </section>
        
        <section>
            <h2>apps.py</h2>
            <pre><code>from django.apps import AppConfig


class ResultsConfig(AppConfig):
    default_auto_field = &quot;django.db.models.BigAutoField&quot;
    name = &quot;apps.domains.results&quot;
    label = &quot;results&quot;
</code></pre>
        </section>
        
        <section>
            <h2>models\__init__.py</h2>
            <pre><code>from .result import Result
from .result_item import ResultItem
from .result_fact import ResultFact

__all__ = [&quot;Result&quot;, &quot;ResultItem&quot;, &quot;ResultFact&quot;]
</code></pre>
        </section>
        
        <section>
            <h2>models\result.py</h2>
            <pre><code>from django.db import models
from apps.api.common.models import BaseModel


class Result(BaseModel):
    &quot;&quot;&quot;
    ÏãúÌóò/ÏàôÏ†ú Í≤∞Í≥º ÏµúÏã† Ïä§ÎÉÖÏÉ∑ (Ï°∞ÌöåÏö©)
    Í≥ÑÏÇ∞ ÏóÜÏùå
    &quot;&quot;&quot;

    target_type = models.CharField(max_length=20)  # exam / homework
    target_id = models.PositiveIntegerField()

    enrollment_id = models.PositiveIntegerField()

    total_score = models.FloatField(default=0.0)
    max_score = models.FloatField(default=0.0)

    submitted_at = models.DateTimeField(null=True, blank=True)

    class Meta:
        db_table = &quot;results_result&quot;
        unique_together = (&quot;target_type&quot;, &quot;target_id&quot;, &quot;enrollment_id&quot;)
</code></pre>
        </section>
        
        <section>
            <h2>models\result_fact.py</h2>
            <pre><code>from django.db import models
from apps.api.common.models import BaseModel


class ResultFact(BaseModel):
    &quot;&quot;&quot;
    Í≤∞Í≥º Fact (append-only, Î∂àÎ≥Ä)
    &quot;&quot;&quot;

    target_type = models.CharField(max_length=20)
    target_id = models.PositiveIntegerField()

    enrollment_id = models.PositiveIntegerField()
    submission_id = models.PositiveIntegerField()

    question_id = models.PositiveIntegerField()

    answer = models.TextField(blank=True)
    is_correct = models.BooleanField(default=False)

    score = models.FloatField(default=0.0)
    max_score = models.FloatField(default=0.0)

    source = models.CharField(max_length=20)
    meta = models.JSONField(null=True, blank=True)

    class Meta:
        db_table = &quot;results_fact&quot;
        ordering = [&quot;-id&quot;]
</code></pre>
        </section>
        
        <section>
            <h2>models\result_item.py</h2>
            <pre><code>from django.db import models
from apps.api.common.models import BaseModel


class ResultItem(BaseModel):
    &quot;&quot;&quot;
    Î¨∏Ìï≠Î≥Ñ ÏµúÏã† Í≤∞Í≥º ÏÉÅÌÉú (snapshot)
    &quot;&quot;&quot;

    result = models.ForeignKey(
        &quot;results.Result&quot;,
        on_delete=models.CASCADE,
        related_name=&quot;items&quot;,
    )

    question_id = models.PositiveIntegerField()

    answer = models.TextField(blank=True)
    is_correct = models.BooleanField(default=False)

    score = models.FloatField(default=0.0)
    max_score = models.FloatField(default=0.0)

    source = models.CharField(max_length=20)

    class Meta:
        db_table = &quot;results_result_item&quot;
        unique_together = (&quot;result&quot;, &quot;question_id&quot;)
</code></pre>
        </section>
        
        <section>
            <h2>services\__init__.py</h2>
            <pre><code>from .applier import ResultApplier

__all__ = [&quot;ResultApplier&quot;]
</code></pre>
        </section>
        
        <section>
            <h2>services\applier.py</h2>
            <pre><code>from django.db import transaction
from django.utils import timezone

from apps.domains.results.models import Result, ResultItem, ResultFact


class ResultApplier:
    &quot;&quot;&quot;
    Í≥ÑÏÇ∞Îêú Í≤∞Í≥ºÎ•º Î∞õÏïÑ resultsÏóê Î∞òÏòÅ
    ‚ùå Í≥ÑÏÇ∞ ÏóÜÏùå
    &quot;&quot;&quot;

    @staticmethod
    @transaction.atomic
    def apply(
        *,
        target_type: str,
        target_id: int,
        enrollment_id: int,
        submission_id: int,
        items: list[dict],
    ) -&gt; Result:
        &quot;&quot;&quot;
        items format:
        {
            question_id,
            answer,
            is_correct,
            score,
            max_score,
            source,
            meta
        }
        &quot;&quot;&quot;

        result, _ = Result.objects.get_or_create(
            target_type=target_type,
            target_id=target_id,
            enrollment_id=enrollment_id,
        )

        total = 0.0
        max_total = 0.0

        for item in items:
            # 1Ô∏è‚É£ Fact
            ResultFact.objects.create(
                target_type=target_type,
                target_id=target_id,
                enrollment_id=enrollment_id,
                submission_id=submission_id,
                **item,
            )

            # 2Ô∏è‚É£ Snapshot
            ResultItem.objects.update_or_create(
                result=result,
                question_id=item[&quot;question_id&quot;],
                defaults={
                    &quot;answer&quot;: item[&quot;answer&quot;],
                    &quot;is_correct&quot;: item[&quot;is_correct&quot;],
                    &quot;score&quot;: item[&quot;score&quot;],
                    &quot;max_score&quot;: item[&quot;max_score&quot;],
                    &quot;source&quot;: item[&quot;source&quot;],
                },
            )

            total += item[&quot;score&quot;]
            max_total += item[&quot;max_score&quot;]

        result.total_score = total
        result.max_score = max_total
        result.submitted_at = timezone.now()
        result.save(update_fields=[&quot;total_score&quot;, &quot;max_score&quot;, &quot;submitted_at&quot;])

        return result
</code></pre>
        </section>
        
        <section>
            <h2>services\grader.py</h2>
            <pre><code># apps/domains/results/services/grader.py
from __future__ import annotations

from typing import Any, Dict, List, Optional, Tuple

from django.db import transaction

from apps.domains.submissions.models import Submission, SubmissionAnswer
from apps.domains.results.services.applier import ResultApplier
from apps.domains.exams.models import ExamQuestion, AnswerKey


# ============================================================
# OMR/Ï±ÑÏ†ê Ï†ïÏ±Ö v1 (Results ÎèÑÎ©îÏù∏ Ï±ÖÏûÑ)
# - WorkerÎäî &quot;ÎãµÏïà ÏÇ¨Ïã§&quot;Îßå Î≥¥ÎÇ¥Í≥†, Ï†êÏàò Í≥ÑÏÇ∞ÏùÄ Ïó¨Í∏∞ÏÑú ÌïúÎã§.
# - v1 Í≥†Ï†ï Ï†ïÏ±Ö:
#   - multi ÎßàÌÇπ = 0Ï†ê
#   - confidence &lt; 0.70 = 0Ï†ê
#   - status != ok = 0Ï†ê
#   - Î∂ÄÎ∂ÑÏ†êÏàò ÏóÜÏùå
# ============================================================

OMR_CONF_THRESHOLD_V1 = 0.70


def _norm(s: Optional[str]) -&gt; str:
    return (s or &quot;&quot;).strip().upper()


def _get_omr_meta(meta: Any) -&gt; Dict[str, Any]:
    &quot;&quot;&quot;
    SubmissionAnswer.metaÏóêÏÑú OMR v1 payload Ï∂îÏ∂ú.
    Í∏∞ÎåÄ ÏúÑÏπò: meta[&quot;omr&quot;]
    &quot;&quot;&quot;
    if not isinstance(meta, dict):
        return {}
    omr = meta.get(&quot;omr&quot;)
    return omr if isinstance(omr, dict) else {}


def _grade_choice_v1(
    *,
    detected: List[str],
    marking: str,
    confidence: Optional[float],
    status: str,
    correct_answer: str,
    max_score: float,
) -&gt; Tuple[bool, float]:
    &quot;&quot;&quot;
    Í∞ùÍ¥ÄÏãù(ÏÑ†ÌÉùÌòï) Ï±ÑÏ†ê v1
    return: (is_correct, score)
    &quot;&quot;&quot;
    if (status or &quot;&quot;).lower() != &quot;ok&quot;:
        return (False, 0.0)

    m = (marking or &quot;&quot;).lower()
    if m in (&quot;blank&quot;, &quot;multi&quot;):
        return (False, 0.0)

    conf = float(confidence) if confidence is not None else 0.0
    if conf &lt; OMR_CONF_THRESHOLD_V1:
        return (False, 0.0)

    if not detected or len(detected) != 1:
        return (False, 0.0)

    ans = _norm(detected[0])
    cor = _norm(correct_answer)

    is_correct = (ans != &quot;&quot;) and (cor != &quot;&quot;) and (ans == cor)
    score = float(max_score) if is_correct else 0.0
    return (is_correct, score)


def _grade_short_v1(
    *,
    answer_text: str,
    correct_answer: str,
    max_score: float,
) -&gt; Tuple[bool, float]:
    &quot;&quot;&quot;
    Ï£ºÍ¥ÄÏãù(ÌÖçÏä§Ìä∏) Ï±ÑÏ†ê v1 (exact match only)
    &quot;&quot;&quot;
    ans = _norm(answer_text)
    cor = _norm(correct_answer)

    if ans == &quot;&quot;:
        return (False, 0.0)

    is_correct = (cor != &quot;&quot;) and (ans == cor)
    score = float(max_score) if is_correct else 0.0
    return (is_correct, score)


def _infer_answer_type(q: ExamQuestion) -&gt; str:
    &quot;&quot;&quot;
    answer_typeÍ∞Ä Î™®Îç∏Ïóê ÏóÜÏùÑ ÏàòÎèÑ ÏûàÏúºÎãà Î∞©Ïñ¥Ï†ÅÏúºÎ°ú Ï∂îÎ°†.
    &quot;&quot;&quot;
    v = getattr(q, &quot;answer_type&quot;, None)
    if isinstance(v, str) and v.strip():
        return v.strip().lower()
    return &quot;choice&quot;


def _get_correct_answer_map(exam_id: int) -&gt; Dict[str, Any]:
    &quot;&quot;&quot;
    AnswerKey.answers: { &quot;1&quot;: &quot;B&quot;, &quot;2&quot;: &quot;3&quot;, ... } (question number Í∏∞Î∞ò)
    &quot;&quot;&quot;
    ak = AnswerKey.objects.filter(exam_id=exam_id).first()
    if not ak or not isinstance(ak.answers, dict):
        return {}
    return ak.answers


@transaction.atomic
def grade_submission_to_results(submission: Submission) -&gt; None:
    &quot;&quot;&quot;
    Submission + SubmissionAnswer(+meta) -&gt; Result/ResultItem/ResultFact Î∞òÏòÅ
    - Ï†ïÏ±Ö/Ï†êÏàò Í≥ÑÏÇ∞ÏùÄ Results ÎèÑÎ©îÏù∏ Ï±ÖÏûÑ
    &quot;&quot;&quot;
    submission.status = Submission.Status.GRADING
    submission.save(update_fields=[&quot;status&quot;])

    answers = list(SubmissionAnswer.objects.filter(submission=submission))

    if submission.target_type != Submission.TargetType.EXAM:
        raise ValueError(&quot;Only exam grading is supported&quot;)

    # ‚úÖ ExamQuestionÏùÄ sheet-&gt;exam Íµ¨Ï°∞
    questions = (
        ExamQuestion.objects
        .filter(sheet__exam_id=submission.target_id)
        .in_bulk(field_name=&quot;id&quot;)
    )

    # ‚úÖ Ï†ïÎãµÏùÄ AnswerKey.answersÏóêÏÑú (question.number Í∏∞Ï§Ä)
    correct_map = _get_correct_answer_map(int(submission.target_id))

    items: List[dict] = []

    for sa in answers:
        q = questions.get(sa.question_id)
        if not q:
            continue

        max_score = float(getattr(q, &quot;score&quot;, 0) or 0.0)

        # question.number Í∏∞Î∞ò Ï†ïÎãµ
        correct_answer = str(correct_map.get(str(getattr(q, &quot;number&quot;, &quot;&quot;))) or &quot;&quot;)

        answer_text = str(sa.answer or &quot;&quot;).strip()

        omr = _get_omr_meta(sa.meta)
        omr_version = str(omr.get(&quot;version&quot;) or &quot;&quot;)
        detected = omr.get(&quot;detected&quot;) or []
        marking = str(omr.get(&quot;marking&quot;) or &quot;&quot;)
        confidence = omr.get(&quot;confidence&quot;, None)
        status = str(omr.get(&quot;status&quot;) or &quot;&quot;)

        answer_type = _infer_answer_type(q)

        if answer_type in (&quot;choice&quot;, &quot;omr&quot;, &quot;multiple_choice&quot;):
            if omr_version.lower() == &quot;v1&quot; and isinstance(detected, list):
                is_correct, score = _grade_choice_v1(
                    detected=[str(x) for x in detected],
                    marking=marking,
                    confidence=(float(confidence) if confidence is not None else None),
                    status=status,
                    correct_answer=correct_answer,
                    max_score=max_score,
                )
                final_answer = &quot;&quot;.join([_norm(x) for x in detected]) if detected else &quot;&quot;
            else:
                is_correct, score = _grade_short_v1(
                    answer_text=answer_text,
                    correct_answer=correct_answer,
                    max_score=max_score,
                )
                final_answer = answer_text
        else:
            is_correct, score = _grade_short_v1(
                answer_text=answer_text,
                correct_answer=correct_answer,
                max_score=max_score,
            )
            final_answer = answer_text

        items.append(
            {
                &quot;question_id&quot;: q.id,
                &quot;answer&quot;: final_answer,
                &quot;is_correct&quot;: bool(is_correct),
                &quot;score&quot;: float(score),
                &quot;max_score&quot;: float(max_score),
                &quot;source&quot;: submission.source,
                &quot;meta&quot;: sa.meta,
            }
        )

    ResultApplier.apply(
        target_type=submission.target_type,
        target_id=int(submission.target_id),
        enrollment_id=int(submission.enrollment_id or 0),
        submission_id=int(submission.id),
        items=items,
    )

    submission.status = Submission.Status.DONE
    submission.save(update_fields=[&quot;status&quot;])
</code></pre>
        </section>
        
        <section>
            <h2>tasks\__init__.py</h2>
            <pre><code></code></pre>
        </section>
        
        <section>
            <h2>tasks\grading_tasks.py</h2>
            <pre><code># apps/domains/results/tasks/grading_tasks.py
from celery import shared_task

from apps.domains.submissions.models import Submission
from apps.domains.results.services.grader import grade_submission_to_results


@shared_task(bind=True, autoretry_for=(Exception,), retry_kwargs={&quot;max_retries&quot;: 3})
def grade_submission_task(self, submission_id: int) -&gt; bool:
    submission = Submission.objects.get(id=submission_id)
    grade_submission_to_results(submission)
    return True
</code></pre>
        </section>
        
        <section>
            <h2>urls.py</h2>
            <pre><code></code></pre>
        </section>
        
        <section>
            <h2>views\__init__.py</h2>
            <pre><code></code></pre>
        </section>
        
        <section>
            <h2>views\exam_result_view.py</h2>
            <pre><code></code></pre>
        </section>
        
        <section>
            <h2>views\homework_result_view.py</h2>
            <pre><code></code></pre>
        </section>
        
        <section>
            <h2>views.py</h2>
            <pre><code># exam_result_view.py / homework_result_view.py
# Ï°∞Ìöå APIÎßå Íµ¨ÌòÑ (ÏßÄÍ∏àÏùÄ ÏÉùÎûµ Í∞ÄÎä•)
</code></pre>
        </section>
        
</body>
</html>
